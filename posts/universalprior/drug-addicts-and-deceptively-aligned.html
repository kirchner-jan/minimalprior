<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="" >

<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <meta name="author" content="Jan Kirchner" />
      <meta name="dcterms.date" content="2024-08-31" />
        <title>minimalprior</title>
    <link rel="stylesheet" href="../../reset.css" />
    <link rel="stylesheet" href="../../index.css" />
      </head>

<body>
    <table class="header">
    <tr>
      <td colspan="2" rowspan="2" class="width-auto">
        <h1 class="title"><a href="https://kirchner-jan.github.io/minimalprior/"
            style="text-decoration: none; color: inherit;">minimalprior</a></h1>
        <span class="subtitle">a spinoff</span>
      </td>
      <th>Updated</th>
      <td class="width-min"><time style="white-space: pre;">2024-08-31</time></td>
    </tr>
    <tr>
      <th class="width-min">Author</th>
      <td class="width-auto"><a href="https://universalprior.substack.com/">Jan
Kirchner</a></td>
    </tr>
  </table>
      <nav id="TOC" role="doc-toc">
        <ul class="incremental">
        <li><a href="#addicts-and-ais" id="toc-addicts-and-ais">Addicts
        and AIs</a></li>
        <li><a href="#ontogenesis-and-characteristics-of-an-addict"
        id="toc-ontogenesis-and-characteristics-of-an-addict">Ontogenesis
        and characteristics of an addict</a></li>
        <li><a href="#instrumental-convergence-in-addicts-and-ais"
        id="toc-instrumental-convergence-in-addicts-and-ais">Instrumental
        convergence in addicts and AIs</a></li>
        <li><a href="#deceptiveness-in-addicts-and-ais"
        id="toc-deceptiveness-in-addicts-and-ais">Deceptiveness in
        addicts and AIs</a></li>
        <li><a
        href="#epistemic-transfer-from-drug-addiction-therapy-to-ai-safety"
        id="toc-epistemic-transfer-from-drug-addiction-therapy-to-ai-safety">Epistemic
        transfer from drug addiction therapy to AI safety</a></li>
        <li><a href="#limitations-and-conclusions"
        id="toc-limitations-and-conclusions">Limitations and
        Conclusions</a></li>
        </ul>
  </nav>
    <p>Edit: The nice folks at the <a
    href="https://forum.effectivealtruism.org/posts/JTZTBienqWEAjGDRv/listen-to-more-ea-content-with-the-nonlinear-library">Nonlinear
    Library</a> turned this post into an audio version <a
    href="https://podcasts.google.com/feed/aHR0cHM6Ly9zcGt0LmlvL2YvODY5Mi83ODg4L3JlYWRfODYxN2QzYWVlNTNmM2FiODQ0YTMwOWQzNzg5NWMxNDM/episode/cEZYRUc5QzVtMlg1aDJ5aXE?sa=X&amp;ved=0CAgQuIEEahgKEwi4yLOmrfj0AhUAAAAAHQAAAAAQngM">here</a>.</p>
    <h3 id="addicts-and-ais">Addicts and AIs</h3>
    <p><em>A young man, let’s call him Dave<sup>[1]</sup>, starts
    consuming different kinds of illegal drugs (mostly heroin) as early
    as age 14, as a reaction to the divorce of his parents. Even though
    he is from an otherwise stable family, he becomes homeless after
    fights about his drug consumption. Repeatedly, Dave returns to his
    family’s home, crying and asking to sleep on the couch for a few
    nights. Repeatedly, the family takes him in, believing that this
    time he finally has a change of heart. And time and time again, Dave
    will disappear after a few days, taking with him all money or any
    other valuable thing that is not nailed down.</em></p>
    <p>As a doctor on the psych ward, I (Nadia) have encountered
    situations like this over and over. The first few times as a health
    professional, <a
    href="https://en.wikipedia.org/wiki/Scrubs_(season_3)#:~:text=63,of%20Un-Truth%22">you
    might get fooled</a> by a patient with addiction. But soon, you
    learn to be skeptical and stop paying attention to what they
    <em>say</em> they did and how they appeal to your empathy. Instead,
    you start to pay close attention to what you can <em>observe</em>
    people doing (and what others <em>tell</em> you they did). Luckily,
    most doctors are smarter than addicts, especially after the addict’s
    cognitive ability <a
    href="https://www.sciencedirect.com/science/article/abs/pii/S0376871607000816?via%3Dihub">starts
    to decline</a> due to substance abuse. Still, treating addicts
    requires constant vigilance and attention to details and potential
    contradictions. This is a sad state of affairs, but the simple fact
    that “<a
    href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4250346/">addicts</a>
    <a
    href="https://scholar.googleusercontent.com/scholar?q=cache:d_J0tVYoi-YJ:scholar.google.com/+alcoholics+lie&amp;hl=en&amp;as_sdt=0,5#:~:text=All%20alcoholics%20lie.%20It%20is%20intrinsic.">lie</a>”<sup>[2]</sup>
    has become one of the central axioms of psychiatric practice.</p>
    <div class="sidenote">
    <p>[2] </p>
    <p>There are, of course, exceptions to the rule, and figuring out
    those exceptions is an art in itself. Importantly, the propensity of
    addicts to lie <a
    href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2821802/">appears
    to be limited</a> to situations where they can actively gain
    something from the lie.</p>
    </div>
    <p>Intriguingly, a very similar situation has emerged in AI
    Safety<sup>[3]</sup>, albeit from a very different direction. One of
    the central intuition pumps of AI Safety is that of the <a
    href="https://www.alignmentforum.org/tag/paperclip-maximizer">single-minded,
    utility-maximizing artificial agent</a>, whose actions end up being
    harmful due to a misalignment of values. While (luckily!) no pure
    version of this agent exists yet, theoretical studies allow us to
    make inferences about properties that such an agent is likely to
    have. This includes f.e. the properties incentivized by <a
    href="https://en.wikipedia.org/wiki/Instrumental_convergence">instrumental
    convergence</a> or the property of <a
    href="https://www.alignmentforum.org/posts/zthDPAjh9w6Ytbeks/deceptive-alignment">nontrivial
    inner alignment</a>. However, theory is theory, and some have
    questioned the <a
    href="https://www.alignmentforum.org/posts/WxW6Gc6f2z3mzmqKs/debate-on-instrumental-convergence-between-lecun-russell">likelihood
    of instrumental convergence</a> actually occurring. Examples of
    instrumental convergence remain “<a
    href="https://en.wikipedia.org/wiki/Instrumental_convergence#Hypothetical_examples_of_convergence">hypothetical</a>”
    and we only know of one <a
    href="https://www.youtube.com/watch?v=zkbPdEHEyEI&amp;ab_channel=RobertMiles">reported
    example of inner alignment failure</a> in a computer model. We
    believe that this is problematic, as reality is complex and
    (theoretically) simple concepts can end up being very
    complicated/different in practice.</p>
    <div class="sidenote">
    <p>[3] </p>
    <p>We (Nadia &amp; Jan) sometimes struggle to communicate to friends
    and family why artificial intelligence (AI) safety is a difficult
    problem. There is the pervasive (and intuitive) belief that “
    <em>If</em> we can create truly powerful AI, it will just figure out
    human morality <a
    href="https://www.alignmentforum.org/posts/Nwgdq6kHke5LY692J/alignment-by-default">by
    default</a>. And even <em>if</em> malicious intent should creep into
    the system somehow, we’ll surely notice and “<a
    href="https://medium.com/swlh/can-we-just-turn-off-dangerous-ai-6cf3ca6d83ba">just
    pull the plug</a>”. As an extreme solution, we might just
    figuratively <a href="https://xkcd.com/1450/">“lock” the AI in a
    box</a>. Then we can audit the AI extensively (through interacting
    with it via text) before we decide if we let it out into the world
    or not.” We believe that the example of the deceptive drug addict in
    this post could serve as one (certainly not the only) useful example
    for illustrating the difficulty of safely aligning AI.</p>
    </div>
    <p>In this post, we want to outline how an addict’s astounding
    ability to <a
    href="https://slatestarcodex.com/2014/05/25/apologia-pro-vita-sua/">optimize
    for getting more drugs</a> has striking similarities to the <a
    href="https://deepmind.com/blog/article/Specification-gaming-the-flip-side-of-AI-ingenuity">relentless
    optimization capabilities</a> of modern AI systems. We argue that
    addicts exhibit a weak form of <em>instrumental convergence</em> and
    that <em>deceptiveness</em> naturally emerges in a setting where the
    optimization process requires cooperation from an uncooperative
    interlocutor. The phenomenon of drug addiction might thus serve as a
    useful “real world” example of many of the theoretical predictions
    of the AI Safety community. Additionally, we examine common
    approaches from addiction therapy and evaluate whether they can
    provide insight into the problem of AI safety. Finally, we highlight
    some limitations of this approach.</p>
    <hr />
    <p>If you are running low on time, here is a TL;DR of our
    analysis:</p>
    <p>Drug addicts serve as a real-life example of a(n approximate)
    single-minded utility optimizer</p>
    <p>They show properties consistent with instrumental convergence,
    fulfilling 3 out of 5 features <a
    href="https://www.nickbostrom.com/superintelligentwill.pdf">highlighted
    by Nick Bostrom</a> (resource acquisition, technological perfection,
    and goal-content integrity)</p>
    <p>Addicts use deception extensively as a tool for achieving their
    instrumental values. We interpret this as an extreme form of an <a
    href="https://suspendedreason.com/2021/05/12/epistemic-strategies-pt-1/">epistemic
    strategy</a></p>
    <p>We find potential analogon of addiction therapy for AI
    Safety:</p>
    <ul class="incremental">
    <li><p>Group therapy might be applicable to multipolar scenarios for
    AI development</p></li>
    <li><p>Anti-Craving and substitution medication might translate to
    interpretability work, esp. <a
    href="https://distill.pub/2020/understanding-rl-vision/#model-editing">model
    editing</a></p></li>
    <li><p><a
    href="https://www.bzga.de/home/key-topics/drug-prevention/">Preventive
    measures</a> might translate to <a
    href="https://intelligence.org/files/TechnicalAgenda.pdf">agent
    foundations</a> research</p></li>
    </ul>
    <hr />
    <h3 id="ontogenesis-and-characteristics-of-an-addict">Ontogenesis
    and characteristics of an addict</h3>
    <p><a
    href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6135092/">Koob
    and Volkov</a> define addiction as:</p>
    <blockquote>
    <p><em>a chronically relapsing disorder, characterised by compulsion
    to seek and take the drug, loss of control in limiting intake, and
    emergence of a negative emotional state (eg, dysphoria, anxiety,
    irritability) when access to the drug is prevented.</em></p>
    </blockquote>
    <p>While much of early research has focused solely on the role of
    dopamine and the reward system in addiction, it is now becoming
    clear that the transition from occasional use to chronic use
    involves substantive changes at the molecular, cellular, and
    neurocircuitry levels. Here is <a
    href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1920543/">Adinoff</a>:</p>
    <blockquote>
    <p><em>The persistent release of dopamine during chronic drug use
    progressively recruits limbic brain regions and the prefrontal
    cortex, embedding drug cues into the amygdala […] and involving the
    amygdala, anterior cingulate, orbitofrontal cortex, and dorsolateral
    prefrontal cortex in the obsessive craving for drugs.</em></p>
    </blockquote>
    <p>These structural changes carve out grooves in the addict’s brain
    that can lead to a strong and immediate relapse of recovering
    addicts following a single dose of the drug, a contextual cue, a
    craving sensation, stress, or distress. Another (particularly
    destructive) effect of drug abuse is the hijacking of the reward
    system. <a
    href="https://www.sciencedirect.com/science/article/abs/pii/S1074742702940992">Volkov
    et al</a>:</p>
    <blockquote>
    <p><em>These findings suggest an overall reduction in the
    sensitivity of the reward circuits in the drug-addicted individual
    to natural reinforcers and possibly to drugs that are not the drug
    of addiction, thereby providing a putative mechanism underlying the
    [sadness and discomfort] experienced during withdrawal.</em></p>
    </blockquote>
    <p>As a consequence, addicts can become extremely single-minded in
    their desires: they lose interest in <a
    href="https://pubmed.ncbi.nlm.nih.gov/21933297/">food</a>, <a
    href="https://www.sciencedirect.com/science/article/abs/pii/S0306460302002666">sex</a>,
    and their <a
    href="https://www.ncbi.nlm.nih.gov/books/NBK248421/box/ch6.box5/?report=objectonly">previous
    social circle</a>, creating a vicious cycle of progressive bodily
    and mental decline. In the language of moral philosophy, drug use
    evolves from having <a
    href="https://www.sciencedirect.com/science/article/pii/S0166432820303715">instrumental
    value</a> (f.e. to disinhibit, to improve performance, or to
    alleviate pain) to having intrinsic value (drug use for reducing the
    desire for drugs).</p>
    <p>Interestingly, the further the addiction progresses, <a
    href="https://www.jstor.org/stable/1830469">the more the addict
    resembles a rational expected utility maximizer</a><sup>[4]</sup>.
    Consistently, the <a
    href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3866817/">escalation
    of drug use</a> is a hallmark of addiction and addicts rapidly
    deplete <a
    href="https://www.tandfonline.com/doi/full/10.1080/02673843.2021.1908376">social
    and financial capital</a> to enable continued drug use. They
    resemble thus the archetypical<sup>[5]</sup> <a
    href="https://www.huffpost.com/entry/artificial-intelligence-oxford_n_5689858#:~:text=Suppose%20we%20have%20an%20AI%20whose%20only%20goal%20is%20to%20make%20as%20many%20paper%20clips%20as%20possible.">paperclip
    maximizer</a>:</p>
    <div class="sidenote">
    <p>[4] </p>
    <p>Gaining utility is equated with drug consumption here. There are
    some interesting <a
    href="https://sites.duke.edu/econ206_01_s2011/files/2015/04/14_TeamGrossman_RationalAddiction.pdf">twists
    and turns</a> here about whether it really makes sense to model an
    addict as a <em>rational</em> agent. (This requires f.e. the
    assumption that an addict’s “awareness of the future consequences is
    not impaired.”) For the purpose of this post, it is only important
    that the addict attempts to maximize utility (drugs), not that they
    do so in an optimal/rational way. Also <a
    href="https://imgflip.com/i/5sgmhx">this</a>.</p>
    </div>
    <div class="sidenote">
    <p>[5] </p>
    <p>(and occasionally scoffed at)</p>
    </div>
    <blockquote>
    <p><em>a hypothetical artificial intelligence whose utility function
    values something that humans would consider almost
    worthless</em>.</p>
    </blockquote>
    <hr />
    <h3 id="instrumental-convergence-in-addicts-and-ais">Instrumental
    convergence in addicts and AIs</h3>
    <p>This resemblance is particularly interesting, as addicts share
    additional features with the hypothetical paperclip maximizers. They
    exhibit (a limited form of) <a
    href="https://en.wikipedia.org/wiki/Instrumental_convergence">instrumental
    convergence</a>. Nick Bostrom formulates the <a
    href="https://www.nickbostrom.com/superintelligentwill.pdf">instrumental
    convergence thesis</a> as:</p>
    <blockquote>
    <p><em>Several instrumental values can be identified which are
    convergent in the sense that their attainment would increase the
    chances of the agent’s goal being realized for a wide range of final
    goals and a wide range of situations, implying that these
    instrumental values are likely to be pursued by many intelligent
    agents.</em></p>
    </blockquote>
    <p>Among the instrumental values proposed by <a
    href="https://www.nickbostrom.com/superintelligentwill.pdf">Bostrom</a>
    are:</p>
    <ul class="incremental">
    <li><p><strong>Resource acquisition</strong> : Having more resources
    allows the agent to more efficiently maximize its final goals. In
    the case of addicts, <a
    href="https://journals.sagepub.com/doi/abs/10.1177/0011128715591696?journalCode=cadc">access
    to money for drugs is a common motivation for property crimes</a>
    and other activities including <a
    href="https://journals.sagepub.com/doi/abs/10.1375/acri.35.2.187?journalCode=anja">drug
    sales, and prostitution as well as legitimate income and the
    avoidance of expenditures</a>.</p></li>
    <li><p><strong>Technological perfection</strong> : Seeking more
    efficient ways of transforming some given set of inputs into valued
    outputs. This can be seen for heroin addicts, who often <a
    href="https://www.uofmhealth.org/health-library/uq2454#:~:text=When%20a%20person%20injects%20heroin%20directly%20into%20a%20vein%20or%20smokes%20heroin%2C%20the%20rush%20occurs%20within%20seconds%2C%20whereas%20it%20takes%20at%20least%2010%20minutes%20when%20the%20drug%20is%20sniffed.">transition
    from snorting or smoking heroin to injecting it intravenously</a> to
    <a
    href="https://americanaddictioncenters.org/heroin-treatment/snorting#:~:text=eventually%20turn%20to%20smoking%20or%20injection">increase
    the intensity of the high</a>.</p></li>
    <li><p><strong>Goal-content integrity</strong><sup>[6]</sup>:
    Preventing alterations of the final goals. Even though this is
    (probably) not executed intentionally by the individual addict, the
    formation of and the involvement in <a
    href="https://www.ncbi.nlm.nih.gov/books/NBK248421/">drug
    culture</a> constantly reinforces the addict’s relationship with the
    drug<sup>[7]</sup>. As drug cultures explicitly <a
    href="https://www.ncbi.nlm.nih.gov/books/NBK248421/box/ch6.box5/?report=objectonly">distance
    themselves from the rest of society</a>, they make it more difficult
    for the addict to stop using. In fact, a central step in drug
    recovery programs is to replace the drug culture with a <a
    href="https://www.ncbi.nlm.nih.gov/books/NBK248421/box/ch6.box12/?report=objectonly">culture
    of recovery</a> such as alcoholics anonymous.</p>
    <div class="sidenote">
    <p>[6] </p>
    <p>Okay, yes, this one is a stretch. But hear us out.</p>
    </div>
    <div class="sidenote">
    <p>[7] </p>
    <p>These cultures are highly complex, vary depending on the <a
    href="https://www.ncbi.nlm.nih.gov/books/NBK248421/box/ch6.box2/?report=objectonly">substance
    used, the geographic location, the socioeconomic status of the
    users, change over time</a>, and commonly <a
    href="https://www.tandfonline.com/doi/abs/10.1080/01639620701876486">evolve
    hierarchies</a>.</p>
    </div></li>
    </ul>
    <p>Interestingly, not all instrumental values proposed by Bostrom
    are pursued by addicts:</p>
    <ul class="incremental">
    <li><p><strong>Self-preservation</strong> : Trying to be around in
    the future, to help the agent achieve its present future-oriented
    goal. As mentioned above, mental and physical health tends to
    deteriorate rapidly once substance abuse escalates. In addition, <a
    href="https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1360-0443.1999.9422095.x">suicide
    attempts are very common among</a>addicts. This accentuates <a
    href="https://www.jstor.org/stable/2565738">myopic tendencies that
    are common among drug users</a>.</p></li>
    <li><p><strong>Cognitive enhancement</strong> : Improving
    rationality and intelligence. While there is some work on how
    addicts act <a
    href="https://www.google.com/url?q=https://www.jstor.org/stable/1830469&amp;sa=D&amp;source=docs&amp;ust=1635625398863000&amp;usg=AOvVaw3QOu_XciX94tnKwYecXlUB">rational
    given their circumstances</a>, they do not actively search out
    cognitive enhancement<sup>[8]</sup>. This is presumably because
    cognitive enhancement is not easily achievable compared to other
    instrumental values.</p>
    <div class="sidenote">
    <p>[8] </p>
    <p><a
    href="https://breakingbad.fandom.com/wiki/Gale_Boetticher">Like,
    f.e., an M.S. in organic chemistry</a>. And while there is the myth
    of streetsmart psychopathic addicts, this is not <a
    href="https://psycnet.apa.org/record/2010-07749-002">actually born
    out in the data</a>.</p>
    </div></li>
    </ul>
    <hr />
    <h3 id="deceptiveness-in-addicts-and-ais">Deceptiveness in addicts
    and AIs</h3>
    <p>As we have alluded to in the introduction, beyond being somewhat
    <a
    href="https://www.alignmentforum.org/posts/Y76durQHrfqwgwM5o/lcdt-a-myopic-decision-theory#The_looming_shadow_of_deception">myopic</a>,
    addicts are often also <a
    href="https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks">deceptive</a>.
    Beyond <a
    href="https://onlinelibrary.wiley.com/doi/abs/10.1002/jclp.22894">dishonesty
    towards a therapist about drug use</a>, <a
    href="https://www.sciencedirect.com/science/article/abs/pii/0740547294900825">feigning
    physical illness to receive medication</a>, and <a
    href="https://pubmed.ncbi.nlm.nih.gov/26820418/">extensive
    self-deception</a>, addicts also tend to <a
    href="https://journals.sagepub.com/doi/10.1177/0022042619853299">manipulate
    emotions</a>:</p>
    <blockquote>
    <p><em>Lying and dishonesty are, indeed, quite frequent in people
    with addiction (Ferrari et al., 2008; Sher &amp; Epler, 2004), who
    often tend to manipulate others close to them to continue their
    substance use because they are jeopardized by their addiction and
    intense craving. Some common manipulation tactics refer to making
    empty promises, playing the victim, making excuses for
    irresponsibility, making others feel uncomfortable or guilty with
    the aim of satisfying unreasonable requests, threatening to
    self-harm, and so on.</em></p>
    </blockquote>
    <p>Now, <em>why</em> do addicts deceive? Here we are running into
    issues with our analogy, as there appears to be <a
    href="https://www.alignmentforum.org/posts/Y76durQHrfqwgwM5o/lcdt-a-myopic-decision-theory">no
    fully satisfying definition of AI deception yet</a>. Addicts are
    clearly not myopic enough to rule out deceptive behavior
    entirely<sup>[9]</sup>. While it is somewhat compelling to regard
    drug culture as a mechanism for preserving an addict’s goal over
    time, addicts don’t appear to be under the immediate threat of
    modification that would justify <a
    href="https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks">deceptive
    alignment in the technical sense</a><sup>[10]</sup>. The motivation
    for deceptive behavior rather appears to be an <a
    href="https://suspendedreason.com/2021/05/12/epistemic-strategies-pt-1/">epistemic
    strategy</a>, executed to manipulate beliefs and decisions.
    Suspended Reason <a
    href="https://suspendedreason.com/2021/05/12/epistemic-strategies-pt-1/">writes</a>:</p>
    <div class="sidenote">
    <p>[9] </p>
    <p>In the <a
    href="https://www.alignmentforum.org/posts/Y76durQHrfqwgwM5o/lcdt-a-myopic-decision-theory">linked
    article</a>, myopia (short-sightedness) is proposed as an
    “overapproximation” of non-deceptiveness. In short, an agent that is
    myopic in a strictly technical sense, <em>can’t</em> be deceptive,
    since they can’t plan ahead far enough to come up with something
    really bad. The reverse obviously doesn’t hold: You can clearly
    imagine someone non-myopic, but also non-deceptive.</p>
    </div>
    <div class="sidenote">
    <p>[10] </p>
    <p>The <a
    href="https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/zthDPAjh9w6Ytbeks">linked
    article</a> provides a list of requirements for deceptive alignment
    to arise and one of the requirements is “ <em>The mesa-optimizer
    must expect the threat of modification to eventually go away, either
    due to training ending or because of actions taken by the
    mesa-optimizer.</em> ” We don’t see a clean way for mapping this
    onto the addiction model.</p>
    </div>
    <blockquote>
    <p><em>[L]iving organisms [are] not just physically but
    epistemically manipulable: their ability to anticipate and optimize,
    to short-term and conditionally adapt oneself into greater fitness
    with the environment—is their greatest strength and greatest
    vulnerability. Affect their priors, or their desires and
    preferences, and they may make a different decision. Our expression
    games include but are far from limited to speech—the superset here
    is the manipulation of appearances and the manipulation of
    representations, be it by linguistic account or [symbolic]
    implication.</em></p>
    </blockquote>
    <p>This is intuitively plausible. The addict’s goals (drug use) are
    incompatible with some of the goals (to stop drug use) of some of
    their peers (family, friends, doctors). The addict requires
    cooperation from their peers to achieve instrumental goals (shelter,
    money, prescription). The peers are unwilling to cooperate with the
    addict as long as they believe the addict’s goals are misaligned
    with their own. Thus, the addict is incentivized to behave in a way
    that changes the beliefs of their peers and to pretend to be
    aligned. The result is that the addict uses their model of the peers
    to act and speak in a way that makes them believe that their goals
    are aligned until they achieve their instrumental goal and return to
    the behavior appropriate to achieving their final goal.</p>
    <p>At this point, it is worth pointing out the obvious: these
    epistemic strategies are not unique to addicts. Carefully managing
    other people’s believes is <a
    href="https://www.pnas.org/content/103/45/16823">hypothesized to
    underlie the disproportionately large cortex of humans</a>, is <a
    href="https://www.jstor.org/stable/4534456">present in other
    animals</a><sup>[11]</sup>, and might indeed <a
    href="https://www.overcomingbias.com/2021/06/our-big-wealth-status-mistake.html#more-32881">permeate
    pretty much all of human culture</a>. The single-mindedness of
    addicts in terms of final values just makes them a particularly
    clear case in which to study epistemic manipulation. Simultaneously,
    the pervasiveness of deception (intentional and unintentional) might
    also further compel us to assume deception as the default, rather
    than as a rare property of pathological agents.</p>
    <div class="sidenote">
    <p>[11] </p>
    <p><a
    href="https://www.washingtonpost.com/archive/opinions/1987/09/13/they-lie-cheat-and-maybe-think/032e22d2-5412-4e5d-b328-2ce55a3dc951/">Seagulls
    do it</a>, so we must assume that <a
    href="https://kirchner-jan.github.io/minimalprior/posts/universalprior/soldiers-scouts-and-albatrosses">albatrosses
    do, too</a>.</p>
    </div>
    <hr />
    <h3
    id="epistemic-transfer-from-drug-addiction-therapy-to-ai-safety">Epistemic
    transfer from drug addiction therapy to AI safety</h3>
    <p>Is there something we can learn from drug addiction therapy that
    translates into AI safety?</p>
    <p>Right out of the gate: Addictions of all kinds are among the
    hardest mental disorders to treat, with the <a
    href="https://doi.org/10.1176/APPI.PS.56.10.1282">majority of
    patients relapsing</a> within ten years after successful treatment.
    Nonetheless, success stories exist. From working with patients on
    addiction recovery, we learn that self-motivation is <a
    href="https://www.sciencedirect.com/science/article/abs/pii/S0740547203001259">absolutely</a>
    <a href="https://psycnet.apa.org/buy/2013-40800-001">essential</a>.
    Nobody will stay sober if they don’t want to stay sober (at least
    most of the time). Other predictors are <a
    href="https://www.sciencedirect.com/science/article/abs/pii/S0740547203001259">religion/spirituality,
    family, and their job/career</a>, i.e. their social circle. In the
    language of AI safety, this is consistent with removing goal-content
    integrity as an instrumental goal. The addict must <em>want</em> to
    change and the composition of the social circle (drug culture
    vs. recovery culture) is a strong predictor of how successfully the
    goal-content can be changed.</p>
    <p>Self-motivation alone, however, isn’t enough in most cases. There
    are several additional approaches with wildly varying degrees of
    success:</p>
    <p><strong>Anti-Craving medication</strong> : <a
    href="https://medlineplus.gov/druginfo/meds/a604028.html">Acamprosate</a>
    and <a
    href="https://www.webmd.com/drugs/2/drug-7399/naltrexone-oral/details">Naltrexone</a>
    are among the few medications that are approved for addiction
    treatment. Naltrexone is an opioid antagonist, blocking receptors
    normally causing euphoria from opioid consumption as well as
    endogenous opioids that are released when doing fun stuff.
    Acamprosate is less well understood, but it seems to lower
    cravings.</p>
    <p><em>AI Safety analogon</em> : Similar to the difficulty of
    finding suitable medication for modifying the motivational system in
    humans, <a
    href="https://distill.pub/2020/understanding-rl-vision/">identifying
    the mechanism for the internalized reward model in AI is not
    trivial</a>. Assuming that the reward model can be interpreted, <a
    href="https://distill.pub/2020/understanding-rl-vision/#model-editing">model
    editing</a> appears as a feasible strategy for correcting
    misalignment<sup>[12]</sup>. Similar to an addict, this strategy can
    only be executed with the “cooperation” of the AI, i.e. the lack of
    goal-content integrity, or in an inpatient setting, where the
    actions of the AI are severely restricted.</p>
    <div class="sidenote">
    <p>[12] </p>
    <p>Certainly a less extreme intervention than “<a
    href="https://medium.com/swlh/can-we-just-turn-off-dangerous-ai-6cf3ca6d83ba">just
    pulling the plug</a>”.</p>
    </div>
    <p><strong>Substitution medication</strong> : In some cases, the
    disorder is too severe to aim for abstinence. Reducing harm is key;
    not just for the individual patient, but for society as a whole,
    reducing crimes related to obtaining illegal substances (violent
    crime, sex work). Famous examples include <a
    href="https://www.webmd.com/mental-health/addiction/what-is-methadone">methadone</a>
    and <a
    href="https://go.drugbank.com/drugs/DB00921">buprenorphine</a>,
    which belong to the opioid family, but cause less euphoria than the
    real stuff and are taken by mouth. Methadone and buprenorphine
    connect to the receptors more tightly than diamorphine (Heroin) or
    oxycodone, so that any consumption after taking the substitute won’t
    have the desired effect.</p>
    <p><em>AI Safety analogon</em> : It is interesting to consider
    whether we can (once we have identified a potentially harmful goal
    of an AI) offer non- (or less-) harmful substitutes<sup>[13]</sup>.
    A paperclip maximizer might not be satisfied with anything else than
    paperclips, but the reality is likely to be more nuanced, especially
    in <a
    href="https://aiimpacts.org/event-multipolar-ai-workshop-with-robin-hanson/">multipolar
    scenarios</a>.</p>
    <div class="sidenote">
    <p>[13] </p>
    <p>A reviewer (Leon Lang) made the following interesting remark: “
    <em>from the point of view of the AI, humans that try to make the AI
    satisfied while actually not producing “the real thing” (e.g.,
    paperclips) almost seem like… misaligned humans?</em> ”</p>
    </div>
    <p><strong>Motivational interviewing</strong> : <a
    href="https://en.wikipedia.org/wiki/Motivational_interviewing">This</a>
    can be the start of a longer treatment for substance use disorders.
    Cards with values like love, honesty, or success are handed out to
    the patient and they are asked to pick those that matter most to
    them. The patient is asked to explain why those values are close to
    their heart, and how they incorporate them into their lives. At some
    point or another, there will be a clash between “continue substance
    use” and “basically anything people value”, ideally helping with
    behavior change and resolving ambivalence in favor of intrinsic
    motivation.</p>
    <p><em>AI Safety analogon</em> : In light of how we argued earlier
    how drugs hijack the motivational system and make addicts
    single-minded, motivational interviewing is intended to restore the
    influence of other final values. However, these other values (love,
    honesty, or success) are qualitatively different from drug use, in
    particular, they are a lot less immediately <em>actionable</em>.
    Including those values into the motivational system of AI appears
    desirable<sup>[14]</sup>, but essentially equivalent to the
    alignment problem.</p>
    <div class="sidenote">
    <p>[14] </p>
    <p>Although we can imagine that an excess of either love, honesty,
    or success (especially when optimized with practically unlimited
    cognitive resources) could be just as destructive as drug use.</p>
    </div>
    <p><strong>Group therapy</strong> : All kinds of groups exist, but
    most clinics will, for example, have a group centered around relapse
    prevention. The most famous example of non-medical, but nonetheless
    effective group therapy, is Alcoholics Anonymous. There seems to be
    something particularly effective about having role models and being
    held accountable by peers, who don’t judge you as harshly as your
    relatives might do.</p>
    <p><em>AI Safety analogon</em> : The mental image of an AI Anonymous
    group therapy meetup has undeniable charm. More realistically, we
    could imagine collaborative <a
    href="https://www.alignmentforum.org/posts/AwMb7C72etphiRvah/unsolved-ml-safety-problems#Anomaly_Detection">anomaly
    detection</a> in a <a
    href="https://aiimpacts.org/event-multipolar-ai-workshop-with-robin-hanson/">multipolar
    scenario</a>, where multiple AIs constantly monitor each other for
    evidence of misalignment. This of course requires that either the
    majority of AIs (or <a
    href="https://www.alignmentforum.org/posts/LpM3EAakwYdS6aRKf/what-multipolar-failure-looks-like-and-robust-agent-agnostic">the
    group as a whole</a>) are (/is) aligned most of the time.</p>
    <p><strong>Preventive measures</strong> : Famously, there is no
    glory in prevention; the people responsible likely won’t get the
    reward they deserve. In the case of substance abuse (with its dismal
    prognoses and high costs for society at large), prevention plays a
    particularly important role. Limiting access to
    substances<sup>[15]</sup> (alcohol, first and foremost) and
    advertising, especially for young people, appears to be the most
    promising ways for fewer victims of addiction.</p>
    <div class="sidenote">
    <p>[15] </p>
    <p>While keeping the mistakes of prohibition in mind.</p>
    </div>
    <p><em>AI Safety analogon</em> : This translates into the obvious:
    the best way to fix misalignment is to never have it occur in the
    first place. <a
    href="https://intelligence.org/files/TechnicalAgenda.pdf">In the
    strongest form</a>, this would involve constructing a system with
    certain mathematical guarantees of safety or, if that is not
    possible, to at least come very close to these guarantees.</p>
    <hr />
    <h3 id="limitations-and-conclusions">Limitations and
    Conclusions</h3>
    <p>While there are some striking similarities between addicts and
    AIs, there are some very important differences that limit
    comparability:</p>
    <ol class="incremental" type="1">
    <li>As we have pointed out, the cognitive ability of addicts <a
    href="https://www.sciencedirect.com/science/article/abs/pii/S0376871607000816?via%3Dihub">tends
    to decrease with progressing addiction</a>. This provides a natural
    negative feedback loop that puts an upper bound on the amount of
    harm an addict can cause. Without this negative feedback loop,
    humanity <a
    href="https://unsongbook.com/chapter-33-the-doors-of-perception/">would
    look very different</a><sup>[16]</sup>. This mechanism is, by
    default, not present for AI<sup>[17]</sup>.</li>
    <li>Addicts are humans. To the extent that they are a useful model
    for thinking about AIs, they are also potentially dangerously
    misleading. A lot of our preconceived notions and cultural norms
    still apply to addicts, making them easy for us to model mentally.
    This does not translate to AI, who might (without any deceptive
    intent) <a
    href="https://www.belfercenter.org/publication/coming-ai-hackers#:~:text=If%20I%20asked%20you%20to%20get%20me%20some%20coffee">misunderstand
    everything we say in the most terrible way possible</a>. Thus, we
    propose this analogy not as an intuition pump that can extrapolate
    outside of the bounds of established validity, but rather as a tool
    for inference within these bounds<sup>[18]</sup>.</li>
    </ol>
    <p>In conclusion, we have demonstrated a number of parallels between
    addicts and misaligned AIs: both can be interpreted as utility
    maximizers, both exhibit a form of instrumental convergence and both
    have a tendency to be deceptive. We translate insights from
    addiction treatment into the language of AI Safety and arrive at a
    few interesting ideas that appear to us to be worth exploring in
    future work. Beyond this, we have demonstrated how epistemic
    transfer from other fields into AI Safety can look like and are
    excited about the possibility of investigating this further.</p>
    <div class="sidenote">
    <p>[1] </p>
    <p>Doctor-patient confidentiality requires us to change the details
    and to mix several stories.</p>
    </div>
    <div class="sidenote">
    <p>[16] </p>
    <p>The link leads to a (long) fiction novel by Scott Alexander where
    Mexico is controlled by people constantly high on peyote, who become
    extremely organized and effective as a result. They are scary &amp;
    dangerous.</p>
    </div>
    <div class="sidenote">
    <p>[17] </p>
    <p>Although it is an interesting idea to scale access to compute
    inversely to how high the value of the accumulated reward is.</p>
    </div>
    <div class="sidenote">
    <p>[18] </p>
    <p>What do we know works in addicts, but hasn’t been tried in AI?
    What works in AI, but hasn’t been tried in addicts?</p>
    </div>
    <div class="debug-grid"></div>
  <script src="../../index.js"></script>
</body>

</html>