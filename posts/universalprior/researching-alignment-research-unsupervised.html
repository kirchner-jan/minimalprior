<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="" >

<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <meta name="author" content="Jan Kirchner" />
      <meta name="dcterms.date" content="2022-06-06" />
        <title>minimalprior</title>
    <link rel="stylesheet" href="../../reset.css" />
    <link rel="stylesheet" href="../../index.css" />
      </head>

<body>
    <table class="header">
    <tr>
      <td colspan="2" rowspan="2" class="width-auto">
        <h1 class="title"><a href="https://kirchner-jan.github.io/minimalprior/"
            style="text-decoration: none; color: inherit;">minimalprior</a></h1>
        <span class="subtitle">a spinoff</span>
      </td>
      <th>Updated</th>
      <td class="width-min"><time style="white-space: pre;">2022-06-06</time></td>
    </tr>
    <tr>
      <th class="width-min">Author</th>
      <td class="width-auto"><a href="https://universalprior.substack.com/">Jan
Kirchner</a></td>
    </tr>
  </table>
      <nav id="TOC" role="doc-toc">
        <ul class="incremental">
        <li><a href="#dataset-announcement"
        id="toc-dataset-announcement">Dataset Announcement</a></li>
        <li><a
        href="#rapid-growth-of-ai-alignment-research-from-2012-to-2022-across-two-platforms"
        id="toc-rapid-growth-of-ai-alignment-research-from-2012-to-2022-across-two-platforms">Rapid
        growth of AI Alignment research from 2012 to 2022 across two
        platforms</a></li>
        <li><a
        href="#unsupervised-decomposition-of-ai-alignment-research-into-distinct-clusters"
        id="toc-unsupervised-decomposition-of-ai-alignment-research-into-distinct-clusters">Unsupervised
        decomposition of AI Alignment research into distinct
        clusters</a></li>
        <li><a
        href="#research-dynamics-vary-across-the-identified-clusters"
        id="toc-research-dynamics-vary-across-the-identified-clusters">Research
        dynamics vary across the identified clusters</a></li>
        <li><a
        href="#leveraging-dataset-to-train-an-ai-alignment-research-classifier"
        id="toc-leveraging-dataset-to-train-an-ai-alignment-research-classifier">Leveraging
        dataset to train an AI alignment research classifier</a></li>
        <li><a href="#closing-remarks" id="toc-closing-remarks">Closing
        remarks</a></li>
        </ul>
  </nav>
    <p><em>Meta-meta: You can also find this<a
    href="https://www.alignmentforum.org/posts/FgjcHiWvADgsocE34/a-descriptive-not-prescriptive-overview-of-current-ai">here</a>
    on the Alignment Forum.</em></p>
    <p><em>Meta: In this project, we collected and cataloged AI
    alignment research literature and analyzed the resulting dataset in
    an unbiased way to identify major research directions. We found that
    the field is growing quickly, with several subfields emerging in
    parallel. We looked at the subfields and identified the prominent
    researchers, recurring topics, and different modes of communication
    in each. Furthermore, we found that a classifier trained on AI
    alignment research articles can detect relevant articles that we did
    not originally include in the dataset.</em></p>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_190.png" /></p>
    <h2 id="dataset-announcement">Dataset Announcement</h2>
    <p>In the context of the <a href="https://aisafety.camp/">6th
    AISC</a>, we collected a dataset of alignment research articles from
    a variety of different sources. This dataset is now available for
    download <a
    href="https://the-eye.eu/public/AI/Alignment/moirage_alignment-research-dataset/">here</a>
    and the code for reproducing the scrape is on GitHub <a
    href="https://github.com/moirage/alignment-research-dataset">here</a><sup>[1]</sup>.
    When using the dataset, please cite our manuscript as described in
    the footnote<sup>[2]</sup>.</p>
    <div class="sidenote">
    <p>[2] </p>
    <p>Kirchner, J. H., Smith, L., Thibodeau, J., McDonnell, K., and
    Reynolds, L. ‚ÄúUnderstanding AI alignment research: A Systematic
    Analysis.‚Äù <em>arXiv preprint arXiv:2206.02841</em> (2022).</p>
    </div>
    <div class="sidenote">
    <p>[1] </p>
    <p>We will make some finishing touches on the repository over the
    next few weeks after this post is published.</p>
    </div>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_191.png" />Table
    1: <strong>Different sources of text included in the dataset
    alongside the number of articles per source.</strong> Color of row
    indicates that data was analyzed as AI alignment research articles
    (green) or baseline (gray), or that the articles were added to the
    dataset as a result of the analysis in Fig. 4 (purple). Definition
    of level-0 and level-1 articles in Fig. 4c. For details about our
    collection procedure see the Methods section.</p>
    <p>Here follows an abbreviated version of the <a
    href="https://arxiv.org/abs/2206.02841">full manuscript</a>, which
    contains additional analysis and discussion.</p>
    <h2
    id="rapid-growth-of-ai-alignment-research-from-2012-to-2022-across-two-platforms">Rapid
    growth of AI Alignment research from 2012 to 2022 across two
    platforms</h2>
    <p>After collecting the dataset, we analyzed the two largest
    non-redundant sources of articles, Alignment Forum (AF) and arXiv.
    We found rapid growth in publications on the AF (Fig. 1a) and a
    long-tailed distribution of articles per researcher (Fig. 1b) and
    researchers per article (Fig. 1c). We were surprised to find a
    <em>decrease</em> in publications on the arXiv in recent years, but
    identified the cause for the decrease as spurious and fixed the
    issue in the published dataset (details in Fig. 4).</p>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_192.png" />Figure
    1: <strong>Alignment Research across a community forum and a
    preprint server.</strong> ( <strong>a</strong> ) Number of articles
    published as a function of time on the alignment forum (AF; purple)
    and the arXiv preprint server (arXiv; green). ( <strong>b</strong> )
    Histogram of the number of articles per researcher published on
    either AF or arXiv. Inset shows names of six researchers with more
    than 60 articles. Note the logarithmic y-axis. ( <strong>c</strong>
    ) Histogram of the number of researchers per article on AF (purple)
    and arXiv (green). Note the logarithmic y-axis.</p>
    <h2
    id="unsupervised-decomposition-of-ai-alignment-research-into-distinct-clusters">Unsupervised
    decomposition of AI Alignment research into distinct clusters</h2>
    <p>Given access to this unique dataset, we were curious to see if we
    could identify distinct clusters of research. We mapped the title +
    abstract of each article into vector form using the <a
    href="https://github.com/allenai/specter">Allen Institute for AI‚Äôs
    SPECTER model</a> and reduced the dimensionality of the embedding
    with UMAP (Fig. 2a). The resulting manifold shows a continuum of AF
    posts and arXiv articles (Fig. 2b) and a temporal gradient from the
    top right to the bottom left (Fig. 2c). Using k-means and the <a
    href="https://en.wikipedia.org/wiki/Elbow_method_(clustering)#:~:text=In%20cluster%20analysis%2C%20the%20elbow,number%20of%20clusters%20to%20use.">elbow
    method</a>, we obtain five clusters of research articles that map
    onto distinct regions of the UMAP projection (Fig. 2d).</p>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_193.png" />Figure
    2: <strong>Dimensionality reduction and unsupervised clustering of
    alignment research.</strong> ( <strong>a</strong> ) Schematic of the
    embedding and dimensionality reduction. After concatenating title
    and abstract of articles, we embed the resulting string with the
    Allen SPECTER model40, and then perform UMAP dimensionality
    reduction with n_neighbors=250. ( <strong>b</strong> ) UMAP
    embedding of articles with color indicating the source (AF, purple;
    arXiv, green). ( <strong>c</strong> ) UMAP embedding of articles
    with color indicating date of publication. Arrows superimposed to
    indicate direction of temporal evolution. ( <strong>d</strong> )
    UMAP embedding of articles with color indicating cluster membership
    as determined with k-means (k=5). Inset shows sum of residuals as a
    function of clusters k, with an arrow highlighting the chosen number
    of clusters.</p>
    <p>We were curious to see if the five clusters identified by k-means
    map onto existing distinctions in the field. When identifying the
    most prolific authors in each cluster, we noticed strong
    differences<sup>[3]</sup> (<a
    href="https://kirchner-jan.github.io/minimalprior/posts/universalprior/on-context-and-people?s=w">consistent
    with previous work</a> that suggests that author identity is an
    important indicator of research direction).</p>
    <div class="sidenote">
    <p>[3] </p>
    <p>Except for Stuart Armstrong, who publishes prolifically across
    all clusters.</p>
    </div>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_194.png" />Table
    2: <strong>Researchers with the highest number of articles per
    cluster.</strong> Clusters as determined in Fig. 2, with number of
    articles per cluster ùëÅ. Number in brackets behind researcher name
    indicates number of articles published by that researcher. Note:
    ‚ÄúDiffractor‚Äù is an undisclosed pseudonym.</p>
    <p>By skimming articles in each cluster and given the typical
    research published by the authors, we suggest the following putative
    descriptions of each cluster:</p>
    <ol class="incremental" type="1">
    <li><strong>cluster one</strong> : <em>Agent alignment</em> is
    concerned with the problem of aligning agentic systems, i.e.¬†those
    where an AI performs actions in an environment and is typically
    trained via reinforcement learning.</li>
    <li><strong>cluster two</strong> : <em>Alignment foundations</em>
    research is concerned with <em>deconfusion</em> research, i.e.¬†the
    task of establishing formal and robust conceptual foundations for
    current and future AI Alignment research.</li>
    <li><strong>cluster three</strong> : <em>Tool alignment</em> is
    concerned with the problem of aligning non-agentic (tool) systems,
    i.e.¬†those where an AI transforms a given input into an output. The
    current, prototypical example of tool AIs is the ‚Äúlarge language
    model‚Äù.</li>
    <li><strong>cluster four</strong> : <em>AI governance</em> is
    concerned with how humanity can best navigate the transition to
    advanced AI systems. This includes focusing on the political,
    economic, military, governance, and ethical dimensions.</li>
    <li><strong>cluster five</strong> : <em>Value alignment</em> is
    concerned with understanding and extracting human preferences and
    designing methods that stop AI systems from acting against these
    preferences.</li>
    </ol>
    <p>We note that <strong>these descriptions are chosen to be
    descriptive, not prescriptive</strong>. Our approach has the
    advantage of being (comparatively<sup>[4]</sup>) unbiased and can
    therefore serve as a baseline against which other (more
    prescriptive) descriptions of the landscape can be compared (<a
    href="https://vkrakovna.wordpress.com/2022/06/02/paradigms-of-ai-alignment-components-and-enablers/">Krakovna‚Äôs
    paradigms</a>, <a href="https://futureoflife.org/landscape/">FLI
    landscape</a>, <a
    href="https://www.youtube.com/watch?v=-vsYtevJ2bc&amp;ab_channel=CentreforEffectiveAltruism">Christiano‚Äôs
    landscape</a>, <a
    href="https://www.lesswrong.com/posts/SQ9cZtfrzDJmw9A2m/my-overview-of-the-ai-alignment-landscape-a-bird-s-eye-view">Nanda‚Äôs
    overview</a>, ‚Ä¶). Discrepancies between these descriptions and ours
    can serve as important information for funding agencies (to identify
    neglected areas) and AI Governance researchers (for early
    identification of natural categories for regulation).</p>
    <div class="sidenote">
    <p>[4] </p>
    <p>Remaining biases include:</p>
    </div>
    <h2
    id="research-dynamics-vary-across-the-identified-clusters">Research
    dynamics vary across the identified clusters</h2>
    <p>We further note some properties of the identified clusters (Fig.
    3a). The cluster labeled as ‚Äúalignment foundations‚Äù contains most of
    the seminal work in the field (Fig. 3b,c), but remains largely
    disconnected from the more applied ‚Äúagent alignment‚Äù and ‚Äútool
    alignment‚Äù research (Fig. 3a). Furthermore, most ‚Äúalignment
    foundations‚Äù work is published on the Alignment Forum (Fig. 3d) and
    it has the largest inequality in terms of ‚Äúnumber of articles per
    researcher‚Äù (Fig. 3e). This corroborates an observation that <a
    href="https://www.alignmentforum.org/posts/CpvyhFy9WvCNsifkY/discussion-with-eliezer-yudkowsky-on-agi-interventions#:~:text=Eliezer%20Yudkowsky-,Very%20grim,-.%20I%20think%20that">was
    made before</a>: <strong>While critically important, alignment
    foundations research appears to be poorly integrated into more
    applied alignment research, and the research remains insular and
    pushed by comparatively few researchers</strong>.</p>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_195.png" />Figure
    3: <strong>Characteristics of research clusters corroborate
    potential usefulness of decomposition.</strong> (a) UMAP embedding
    of articles with color indicating cluster membership as in Fig. 2d.
    Labels assigned to each cluster are putative descriptions of a
    common research focus across articles in the cluster. (b) Number of
    articles published per year, colored by cluster membership. (c)
    Fraction of articles published by cluster membership as a function
    of time. (d) Fraction of articles from AF or arXiv as a function of
    cluster membership. (e) GINI inequality coefficient of articles per
    researcher as a function of article cluster membership.</p>
    <h2
    id="leveraging-dataset-to-train-an-ai-alignment-research-classifier">Leveraging
    dataset to train an AI alignment research classifier</h2>
    <p>After having identified the five clusters, we returned to the
    issue we noted at the onset of our analysis: the apparent decrease
    in publications on the arXiv in recent years (Fig. 1a). We were
    skeptical about this and hypothesized that our data collection might
    have missed relevant recent articles<sup>[5]</sup>. Therefore, we
    trained a logistic regression classifier to distinguish alignment
    articles (level-0) from articles cited by alignment articles
    (level-1) (Fig.4 a). The resulting classifier achieved good
    performance and generalized well to papers from unrelated sources
    (Fig. 4b). We then scraped all the articles from the arXiv cs.AI
    category and asked our classifier to score them (Fig. 4c,d). Based
    on the distribution of scores of Alignment Forum posts (Fig. 4d) and
    after skimming the relevant articles, we chose a threshold of 75% as
    a reasonable trade-off between false positives and false
    negatives.</p>
    <div class="sidenote">
    <p>[5] </p>
    <p>We took the <a
    href="https://www.alignmentforum.org/posts/4DegbDJJiMX2b3EKm/tai-safety-bibliographic-database">TAI
    Safety Bibliographic Database</a> from early 2020 as a starting
    point and manually added relevant articles from other existing
    bibliographies or based on our judgment. We were very conservative
    in this step, as we wanted to make sure that our dataset includes as
    few false positives as possible.</p>
    </div>
    <p>When adding the arXiv articles above the cutoff to our dataset,
    we observed a rapid increase in publications also on the arXiv (Fig.
    4e). To test if our clustering is robust to this increase, we
    repeated the UMAP projection with the updated dataset and found
    that, indeed, the clusters are still in distinct regions of the
    manifold (Fig. 4f). Interestingly, the added literature appears to
    fill some of the gaps between ‚Äúalignment foundations‚Äù and ‚Äúagent
    alignment‚Äù research.</p>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_196.png" />Figure
    4: <strong>An AI alignment research classifier for filtering new
    publications.</strong> (a) Top: Illustration of arXiv level-0
    articles (alignment research; green) and level-1 articles (cited by
    alignment research articles; blue). Bottom: Schematic of test-train
    split (20%-80% for training of a logistic regression classifier. (b)
    Fraction of articles as a function of classifier score for arXiv
    level-0 (green), level-1 (blue), and arXiv articles on quantum
    physics (grey). (c) Illustration of procedure for filtering arXiv
    articles. After querying articles from the cs.AI section of arXiv,
    the logistic regression classifier assigns a score between 0 and 1.
    (d) Fraction of articles as a function of classifier score for
    articles from the cs.AI section of arXiv (grey) and AF (purple).
    Dashed line indicates cutoff for classifying articles as arXiv
    level-0 (75%). (e) Number of articles published as a function of
    time on AF (purple) and arXiv (green), according to the cutoff in
    panel d.¬†(f) Left inset: Original UMAP embedding from Fig. 2d.
    Right: UMAP embedding of all original articles and updated arXiv
    articles with color indicating cluster membership as in Fig. 2d or
    that the article is filtered from the arXiv (gray).</p>
    <h2 id="closing-remarks">Closing remarks</h2>
    <p>The primary output from our project is the curated dataset of
    alignment research articles. We hope the dataset might serve as the
    basis for</p>
    <ul class="incremental">
    <li><p>a semantic search service that returns relevant literature
    (see prototype <a
    href="https://share.streamlit.io/kirchner-jan/search-engine/app.py">here</a>).</p></li>
    <li><p><a
    href="https://www.alignmentforum.org/posts/ebYiodG3MAEqskCDG/a-survey-of-tool-use-and-workflows-in-alignment-research-1">writing
    assistants in the form of fine-tuned large-language
    models</a>.</p></li>
    <li><p><a
    href="https://www.lesswrong.com/posts/xrxh3usuoYMckkKom/preserving-and-continuing-alignment-research-through-a">projects
    to preserve AI Safety research in case of catastrophic
    events</a>.</p></li>
    </ul>
    <p>If you have other ideas for how to use the dataset, please don‚Äôt
    hesitate to reach out to us; we‚Äôre excited to help.</p>
    <p>Furthermore, we hope that the secondary outcome from our project
    (the analysis in this post) can aid both funding agencies and new
    researchers entering the field to orient themselves and
    contextualize the research.</p>
    <p>As we plan to continue this line of research, we are happy about
    any and all feedback on the dataset and the analysis, as well as
    hints and pointers about things we might have missed.</p>
    <p><em>Acknowledgments: We thank Daniel Clothiaux for help with
    writing the code and extracting articles. We thank Remmelt Ellen,
    Adam Shimi, and Arush Tagade for feedback on the research. We thank
    Chu Chen, √ñmer Faruk ≈ûen, Hey, Nihal Mohan Moodbidri, and Trinity
    Smith for cleaning the audio transcripts.</em></p>
    <ul class="incremental">
    <li><p>differences in formatting between arxiv and AF articles that
    bias the embedding</p></li>
    <li><p>some (important) topics might not have any documentation due
    to infohazards</p></li>
    <li><p>by implicitly focusing on number of published articles
    (rather than f.e. the ‚Äúvolume occupied in semantic space‚Äù) we bias
    our analysis in favor of questions that can be written about more
    easily</p></li>
    </ul>
    <div class="debug-grid"></div>
  <script src="index.js"></script>
</body>

</html>