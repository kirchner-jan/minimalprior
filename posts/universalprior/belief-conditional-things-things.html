<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="" >

<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <meta name="author" content="Jan Kirchner" />
      <meta name="dcterms.date" content="2024-08-31" />
        <title>minimalprior</title>
    <link rel="stylesheet" href="../../reset.css" />
    <link rel="stylesheet" href="../../index.css" />
      </head>

<body>
    <table class="header">
    <tr>
      <td colspan="2" rowspan="2" class="width-auto">
        <h1 class="title"><a href="https://kirchner-jan.github.io/minimalprior/"
            style="text-decoration: none; color: inherit;">minimalprior</a></h1>
        <span class="subtitle">a spinoff</span>
      </td>
      <th>Updated</th>
      <td class="width-min"><time style="white-space: pre;">2024-08-31</time></td>
    </tr>
    <tr>
      <th class="width-min">Author</th>
      <td class="width-auto"><a href="https://universalprior.substack.com/">Jan
Kirchner</a></td>
    </tr>
  </table>
      <nav id="TOC" role="doc-toc">
        <ul class="incremental">
        <li><a href="#date-2021-12-25" id="toc-date-2021-12-25">date:
        2021-12-25</a></li>
        <li><a href="#do-you-believe" id="toc-do-you-believe"><strong>ğŸµ
        Do you believeâ€¦ ğŸµ</strong></a></li>
        <li><a href="#in-love-after-love"
        id="toc-in-love-after-love"><strong>ğŸµ â€¦ in love after love
        ğŸµ</strong></a></li>
        <li><a href="#gÃ¶dels-trick"
        id="toc-gÃ¶dels-trick"><strong>GÃ¶delâ€™s trick</strong></a></li>
        <li><a href="#no-really-there-_-is_-a-dragon-in-my-garage."
        id="toc-no-really-there-_-is_-a-dragon-in-my-garage."><strong>No,
        really, there</strong> _ <strong>is</strong>_ <strong>a dragon
        in my garage.</strong></a></li>
        <li><a href="#trolling-your-landlord."
        id="toc-trolling-your-landlord."><strong>Trolling your
        landlord.</strong></a></li>
        <li><a href="#closing-thoughts."
        id="toc-closing-thoughts."><strong>Closing
        thoughts.</strong></a></li>
        </ul>
  </nav>
    <h2 id="date-2021-12-25">date: 2021-12-25</h2>
    <h2 id="do-you-believe"><strong>ğŸµ Do you believeâ€¦ ğŸµ</strong></h2>
    <p>It is the season, and I just finished watching the 2003 classic
    â€œ<a href="https://en.wikipedia.org/wiki/Elf_%28film%29">Elf</a>â€
    with Will Ferrell as â€œBuddyâ€, a human raised among elves at the
    North Pole who travels to New York to reunite with his biological
    father and to save Christmas. The movie got me thinking.</p>
    <p>There is an interesting trope in the movie thatâ€™s used as a story
    device: the magical powers of Santa are predicated on humans
    believing in Santa. Thus, Santa falls in the same category as some
    <a href="https://en.wikipedia.org/wiki/Tinkerbell_effect">magical
    creatures</a>, <a
    href="https://www.investopedia.com/terms/f/fiatmoney.asp">the value
    of fiat money</a> and, arguably, god<a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-1-41815715">1</a>.
    To spread some magical fuzzy winter feelings, I want to share some
    thoughts about what I call â€œbelief-conditional thingsâ€. I think Iâ€™m
    on to something here.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc25f2c85-95cf-469b-8251-36c97e0c571f_256x256.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc25f2c85-95cf-469b-8251-36c97e0c571f_256x256.png" /></a>Expect
    me to upgrade my <a
    href="https://githubmemory.com/repo/crowsonkb/v-diffusion-pytorch">CGD</a>
    game even further in the new year! This looks a lot like Santa.</p>
    <h2 id="in-love-after-love"><strong>ğŸµ â€¦ in love after love
    ğŸµ</strong></h2>
    <p>What is the relationship between belief and reality? Some like to
    think in terms of â€œterritory and mapâ€: the territory is everything
    <em>out there</em>. The map is a lossy <em>mental</em>
    representation of the territory. We know that the <a
    href="https://www.lesswrong.com/posts/KJ9MFBPwXGwNpadf2/skill-the-map-is-not-the-territory">map
    is not the territory</a>; sometimes, we are <a
    href="https://universalprior.substack.com/p/frankfurt-declaration-on-the-cambridge">confused
    about how things work</a>, sometimes we <a
    href="https://www.lesswrong.com/posts/tPqQdLCuxanjhoaNs/reductionism">treat
    complex systems as black boxes</a>, and some things are <a
    href="https://xkcd.com/1053/">not represented in our map</a>.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F06741a49-d8e3-48eb-9ad2-f223b6e3adf9_256x256.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F06741a49-d8e3-48eb-9ad2-f223b6e3adf9_256x256.png" /></a>On
    the left thereâ€™s a map, on the right thereâ€™sâ€¦ Middle earth?</p>
    <p>The entire scientific endeavor might be summarized as reducing
    discrepancies between map and territory. Traditionally, you would
    update the map according to what you see in the environment.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3cfb969-51eb-458f-ba2b-ec551052b347_1600x496.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3cfb969-51eb-458f-ba2b-ec551052b347_1600x496.png" /></a>Broke:
    Seeing that there is no dragon in your garage and giving up on the
    belief.</p>
    <p>But if your metric is symmetric (and why would you call it a <a
    href="https://en.wikipedia.org/wiki/Metric_mathematics">metric</a>
    otherwise?) then itâ€™s equally effective to change the territory.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0227e96-7572-42a6-9dcd-d2166212c7d6_1600x462.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0227e96-7572-42a6-9dcd-d2166212c7d6_1600x462.png" /></a>Woke:
    Believing in the dragon so hard that reality changes to match your
    belief.</p>
    <p>Indeed, I think this is what motivates a substantial part of
    moral philosophy<a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-2-41815715">2</a>:
    Instead of accepting the world as it is, we conjure our ideas about
    how things ought to be into reality. Thus, itâ€™s not unheard of that
    reality is affected by our beliefs. This opens the door forâ€¦</p>
    <h2 id="gÃ¶dels-trick"><strong>GÃ¶delâ€™s trick</strong></h2>
    <p>When thinking about existence and belief, it is natural to think
    of <a
    href="https://plato.stanford.edu/entries/logic-epistemic">epistemic
    logic</a> - the subfield of the philosophy of knowledge that
    formalizes how we form and maintain beliefs. This approach allows us
    to derive, under reasonable axioms, that <a
    href="https://link.springer.com/chapter/10.1007/3-540-16761-7_68">belief
    and knowledge collapse</a>. Formally, this means that believing in
    the existence of Santa Claus,</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb718bdbf-8854-4b9b-a835-f5bb35aeede9_502x80.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb718bdbf-8854-4b9b-a835-f5bb35aeede9_502x80.png" /></a></p>
    <p>implies knowledge of the existence of Santa Claus,</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1c87d227-397e-4d86-b37c-5d4b3e35b243_510x80.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1c87d227-397e-4d86-b37c-5d4b3e35b243_510x80.png" /></a></p>
    <p>And then, by using <a
    href="https://en.wikipedia.org/wiki/Modal_logic#Axiomatic_systems">axiom
    T</a>, we immediately arrive at the existence of Santa Claus<a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-3-41815715">3</a>,</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3195e342-9f64-4a18-b41d-c57cefb38f75_432x80.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3195e342-9f64-4a18-b41d-c57cefb38f75_432x80.png" /></a></p>
    <p>I presume that this must be essentially equivalent to <a
    href="https://en.wikipedia.org/wiki/G%C3%B6del%27s_ontological_proof">GÃ¶delâ€™s
    ontological proof</a>, although I (same as everybody else) havenâ€™t
    checked the details. Therefore, I will call this â€œGÃ¶delâ€™s trickâ€<a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-4-41815715">4</a>;
    and epistemic logic turns out to be extremely useful once again.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe9c657b8-048a-4a42-9b68-0ebdf1276521_256x256.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe9c657b8-048a-4a42-9b68-0ebdf1276521_256x256.png" /></a>I
    guess this is supposed to read â€œGÃ¶del, Kurtâ€. Almost, CGD,
    almost.</p>
    <h2 id="no-really-there-_-is_-a-dragon-in-my-garage."><strong>No,
    really, there</strong> _ <strong>is</strong>_ <strong>a dragon in my
    garage.</strong></h2>
    <p>Any good rationalist might now counter: â€œWell, yes, belief might
    imply existence. But you donâ€™t actually believe in
    <strong>X</strong>. You only <a
    href="https://www.lesswrong.com/posts/CqyJzDZWvGhhFJ7dY/belief-in-belief">believe
    that you believe</a> in <strong>X</strong>.â€ The classic example is
    the â€œ<a
    href="http://people.whitman.edu/~herbrawt/classes/110/Sagan.pdf">dragon
    in the garage</a>â€ of Carl Sagan:</p>
    <blockquote>
    <p>â€œA fire-breathing dragon lives in my garageâ€<br />
    Suppose I seriously make such an assertion to you. Surely youâ€™d want
    to check it out, see for yourself. There have been innumerable
    stories of dragons over the centuries, but no real evidence. What an
    opportunity!<br />
    â€œShow me,â€ you say.<br />
    I lead you to my garage. You look inside and see a ladder, empty
    paint cans, an old tricycle â€” but no dragon.<br />
    â€œWhereâ€™s the dragon?â€ you ask.<br />
    â€œOh, sheâ€™s right here,â€ I reply, waving vaguely.<br />
    â€œI neglected to mention that sheâ€™s an invisible dragon.â€<br />
    You propose spreading flour on the floor of the garage to capture
    the dragonâ€™s footprints.<br />
    â€œGood idea,â€ I say, â€œbut this dragon floats in the air.â€<br />
    Then youâ€™ll use an infrared sensor to detect the invisible
    fire.<br />
    â€œGood idea, but the invisible fire is also heatless.â€<br />
    Youâ€™ll spray-paint the dragon and make her visible.<br />
    â€œGood idea, but sheâ€™s an incorporeal dragon and the paint wonâ€™t
    stick.â€<br />
    And so on. I counter every physical test you propose with a special
    explanation of why it wonâ€™t work.</p>
    </blockquote>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Feff78aca-47f2-48b0-9e0a-a4313d7a0399_256x256.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Feff78aca-47f2-48b0-9e0a-a4313d7a0399_256x256.png" /></a>Such
    a cool dragon ğŸ¤©</p>
    <p>Carl Sagan argues that the person claiming a dragon in their
    garage doesnâ€™t <em>actually</em> believe this. Their ability to <a
    href="http://strategicreasoning.org/wp-content/uploads/2010/03/pami93.pdf">explain
    away</a> (ahead of time) all contradicting experimental evidence
    reveals that they accurately model the territory. They know exactly
    what to expect, given that there is no dragon in the garage. They
    might claim to believe <strong>X</strong> , but they only believe
    that they believe <strong>X</strong>.</p>
    <p>But for GÃ¶delâ€™s trick to work, we <em>actually</em> need to
    believe <strong>X</strong>. Thus we have to stick our necks out and
    make falsifiable predictions. Saying, â€œCome to my garage and see the
    dragon. Sheâ€™s really cool!â€ is not the hard part. The hard part is
    <a
    href="https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences">paying
    rent</a>.</p>
    <h2 id="trolling-your-landlord."><strong>Trolling your
    landlord.</strong></h2>
    <p>â€œPaying rentâ€ in this context comes from the rationalist strategy
    of â€œ<a
    href="https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences">making
    your beliefs pay rent</a>â€. Beliefs are only allowed to stay in your
    head if they â€œpayâ€ by making predictions about the world. If those
    predictions cash out, the belief is allowed to stay. If not, they
    will be kicked out. If you continuously claim that there is a dragon
    in your garage, and you make predictions accordingly, eventually the
    belief wonâ€™t be able to pay anymore. Then you wonâ€™t be able to use
    GÃ¶delâ€™s trick.</p>
    <p>But what is the â€œmoneyâ€ here? What is used to pay the rent? And
    what determines how much â€œmoneyâ€ the belief has?</p>
    <p>In a <a
    href="https://en.wikipedia.org/wiki/Bayesian_probability">Bayesian
    framework</a>,<a
    href="https://www.sciencedirect.com/science/article/pii/S0888613X03001506">beliefs
    are akin to probabilities</a> and have a number between zero and one
    <a
    href="https://en.wikipedia.org/wiki/Credence_%28statistics%29">associated
    with them</a>, indicating how strong the belief is. Changes these
    numbers in a systematic way (that incorporates all the evidence
    optimally) is called <a
    href="https://www.lesswrong.com/posts/XTXWPQSEgoMkAupKt/an-intuitive-explanation-of-bayes-s-theorem">Bayesian
    belief updates</a>. On the road to believing <strong>X</strong> into
    existence, you might suffer severe setbacks. If you naively follow
    Bayes, these setbacks will reduce your belief until you end up not
    believing in the <em>belief-conditional thing</em>
    <strong>X</strong> - thus creating a self-fulfilling prophecy.</p>
    <p>Luckily, we are now in the territory of mathematics, a field
    known to be highly susceptible to shenanigans. Most <a
    href="https://www.lesswrong.com/posts/5bd75cc58225bf067037518c/all-mathematicians-are-trollable-divergence-of-naturalistic-logical-updates">mathematicians
    are trollable</a><a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-5-41815715">5</a>.
    It turns out that any Bayesian hit to our belief in
    <strong>X</strong> through new evidence can be counteracted by
    thinking about ways that <strong>X</strong> might be true after all.
    In particular, any sentence <strong>A - &gt; X</strong> that you can
    prove (like <a
    href="https://en.wikipedia.org/wiki/Klaus_film">â€œSanta Claus exists
    and used to be a reclusive toymaker in the Far Northâ€</a> therefore
    â€œSanta Claus existsâ€<a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-6-41815715">6</a>)
    eliminates probability mass of <strong>not X</strong>. Repeated
    sufficiently many times, this procedure should allow us to believe
    in <strong>X</strong> sufficiently strong to believe
    <strong>X</strong> into existence - again, a self-fulfilling
    prophecy. Dreaming about <strong>X</strong> and picturing it with as
    many details as possible is thus a necessary step for making it
    real.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4efbda1a-2e16-4028-a9d8-0bb8cafc6653_256x256.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4efbda1a-2e16-4028-a9d8-0bb8cafc6653_256x256.png" /></a>A
    very formal troll.</p>
    <p>Thus, through several loops and twists, we arrive at what every
    child can already tell you: Making belief-conditional-things exists
    only requires us to believe strongly, picture the thing in as many
    details as possible, and act as if it really can exist. Easy as
    that.</p>
    <h2 id="closing-thoughts."><strong>Closing thoughts.</strong></h2>
    <p>Through the examples I have listed in the first section, I might
    have deceived you into exclusively thinking about fantastic and
    mystical creatures. But those are (by far) not the only examples of
    things that can only exist when we believe in them. <a
    href="https://www.youtube.com/watch?v=0agVZwux1Hs">Mars
    colonies</a>, <a
    href="https://www.nature.com/articles/nrd.2017.243">curing
    cancer</a>, and peace on earth are additional examples - in fact,
    most good things in the future are belief-conditional. Following the
    argument outlined above, we can believe belief-conditional thing
    <strong>X</strong> into existence by doing the following things: By
    changing the territory rather than our map, by providing as many
    viable avenues to achieve <strong>X</strong> as possible, and by
    sticking our necks out to perform tests while actually believing in
    the possibility of <strong>X</strong>. There might be more things we
    can do, and most of the ones I list might not apply in all
    situations. But this is for you to find out.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd3b6d2-9955-42ee-bff3-6dce2d4cebda_256x256.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2fd3b6d2-9955-42ee-bff3-6dce2d4cebda_256x256.png" /></a>A
    winter wonderland.</p>
    <p>Thank you, dear reader. Happy holidays.</p>
    <p>Subscribe</p>
    <p><a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-anchor-1-41815715">1</a></p>
    <p>as explained in the <a
    href="http://unsongbook.com/chapter-3-on-a-cloud-i-saw-a-child/">Book
    of Jezuboad</a> and discussed <a
    href="https://brill.com/view/journals/jocc/8/1-2/article-p149_8.xml">here</a></p>
    <p><a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-anchor-2-41815715">2</a></p>
    <p>and, for that matter,<a
    href="https://en.wikipedia.org/wiki/Live_action_role-playing_game">larping</a>.</p>
    <p><a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-anchor-3-41815715">3</a></p>
    <p>Please donâ€™t send me messages about how this is wrong. I
    <em>want</em> to believe.</p>
    <p><a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-anchor-4-41815715">4</a></p>
    <p>My Substack, my rules.</p>
    <p><a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-anchor-5-41815715">5</a></p>
    <p>Admittedly,<a
    href="https://www.lesswrong.com/posts/CvKnhXTu9BPcdKE4W/an-untrollable-mathematician-illustrated">not
    every prior is trollable in this way</a>, but last time I checked,
    the choice of prior is personal. So the power to believe is
    ours.</p>
    <p><a
    href="https://universalprior.substack.com/p/belief-conditional-things-things#footnote-anchor-6-41815715">6</a></p>
    <p>This <em>is</em> a valid inference (the antecedent does, in fact,
    imply the succedent) and even a true statement (if the antecedent is
    false, the implication is always true)!</p>
    <div class="debug-grid"></div>
  <script src="index.js"></script>
</body>

</html>