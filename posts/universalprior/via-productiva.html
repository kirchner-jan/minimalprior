<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="" >

<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <meta name="author" content="Jan Kirchner" />
      <meta name="dcterms.date" content="2022-03-06" />
        <title>Via productiva</title>
    <link rel="stylesheet" href="../../reset.css" />
    <link rel="stylesheet" href="../../index.css" />
      </head>

<body>
    <table class="header">
    <tr>
      <td colspan="2" rowspan="2" class="width-auto">
        <h1 class="title"><a href="https://kirchner-jan.github.io/minimalprior/"
            style="text-decoration: none; color: inherit;">Via
productiva</a></h1>
        <span class="subtitle">Be careful whose advice you buy, but be
patient with those who supply it. Advice is a form of nostalgia,
dispensing it is a way of fishing the past from…</span>
      </td>
      <th>Updated</th>
      <td class="width-min"><time style="white-space: pre;">2022-03-06</time></td>
    </tr>
    <tr>
      <th class="width-min">Author</th>
      <td class="width-auto"><a href="https://kirchner-jan.github.io/minimalprior/">Jan
Kirchner</a></td>
    </tr>
  </table>
      <nav id="TOC" role="doc-toc">
        <ul class="incremental">
        <li><a href="#against-advice"
        id="toc-against-advice"><strong>Against advice</strong></a></li>
        <li><a href="#the-negative-way" id="toc-the-negative-way">The
        negative way</a></li>
        <li><a href="#dont-fight-the-hydra."
        id="toc-dont-fight-the-hydra."><strong>Don’t fight the
        Hydra.</strong></a></li>
        <li><a href="#one-must-imagine-sisyphus-unproductive."
        id="toc-one-must-imagine-sisyphus-unproductive."><strong>One
        must imagine Sisyphus unproductive</strong>.</a></li>
        <li><a href="#dont-listen-to-cassandra."
        id="toc-dont-listen-to-cassandra."><strong>Don’t listen to
        Cassandra.</strong></a></li>
        <li><a href="#closing-thoughts"
        id="toc-closing-thoughts">Closing thoughts</a></li>
        </ul>
  </nav>
    <h2 id="against-advice"><strong>Against advice</strong></h2>
    <blockquote>
    <p>Be careful whose advice you buy, but be patient with those who
    supply it. Advice is a form of nostalgia, dispensing it is a way of
    fishing the past from the disposal, wiping it off, painting over the
    ugly parts and recycling it for more than it’s worth. - <a
    href="https://www.youtube.com/watch?v=sTJ7AzBIJoI&amp;ab_channel=steffyweffy777">Everybody’s
    Free To Wear Sunscreen</a></p>
    </blockquote>
    <p>…</p>
    <p>Yeah, I’m not a huge fan of advice.</p>
    <p>I think there are many good side effects of giving and receiving
    advice. The act of giving advice is essentially an <a
    href="https://kirchner-jan.github.io/minimalprior/posts/universalprior/trust-maximizing-agi?s=w">expression
    of trust</a>, “asking for help” is a <a
    href="https://torch.io/blog/leadership-the-power-of-asking-for-help/">social
    superpower</a>, and the downsides of being exposed to information
    are <em>usually</em> rather low<sup>[1]</sup>. But those are just
    side effects; the actual core purpose of advice (exchanging relevant
    and helpful information) is surprisingly hard to get right:</p>
    <div class="sidenote">
    <p>[1] </p>
    <p>Unless somebody manages to trick you into <a
    href="https://stevemay.com/category/wisdom/#:~:text=told%20his%20grandchild%3A%20%E2%80%9C-,If,-you%20see%20a">bear-assisted
    suicide</a>.</p>
    </div>
    <ol class="incremental" type="1">
    <li><p>Causality is <a
    href="https://arxiv.org/pdf/2109.11513.pdf">complicated</a>. <a
    href="http://www.scholarpedia.org/article/Reinforcement_learning#.28Temporal.29_Credit_Assignment_Problem">Figuring
    out why you succeeded</a> is hard, and the story you tell yourself
    about it is probably wrong. <img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_76.png" /><a
    href="https://xkcd.com/1827/">source</a></p></li>
    <li><p>For almost any piece of advice out there, you can find <a
    href="https://slatestarcodex.com/2014/03/24/should-you-reverse-any-advice-you-hear/">reverse
    advice</a>, i.e. &gt; “You need to stop being so hard on yourself,
    remember you are your own worst critic” versus “Stop making excuses
    for yourself, you will never be able to change until you admit
    you’ve hit bottom.” <a
    href="https://slatestarcodex.com/2014/03/24/should-you-reverse-any-advice-you-hear/">SSC</a></p></li>
    </ol>
    <p>and because of your <a
    href="https://slatestarcodex.com/2017/10/02/different-worlds/">social
    bubble</a>, you might be exposed to advice with exactly the wrong
    polarity<sup>[2]</sup>.</p>
    <div class="sidenote">
    <p>[2] </p>
    <p>I.e. addicts that are part of a <a
    href="https://www.ncbi.nlm.nih.gov/books/NBK248421/">drug
    culture</a> might get the advice to take more drugs. Or rationalists
    might get the advice to <a
    href="https://www.lesswrong.com/posts/qmXqHKpgRfg83Nif9/how-to-ignore-your-emotions-while-also-thinking-you-re">use
    more rationality techniques</a>.</p>
    </div>
    <ol class="incremental" type="1">
    <li>The people with the most relevant insight are probably busy
    <em>doing</em> stuff, leaving the people with a lot of free time on
    their hands to dominate the advice-giving market. So most people who
    want to give (or sell) advice do not have the relevant insight to
    give <em>good</em> advice. This effect corroborates the <a
    href="https://marginalrevolution.com/marginalrevolution/2021/12/two-all-purpose-pieces-of-advice-small-groups-and-mentors.html">importance
    of having mentors</a>; even busy people want to give advice but are
    more selective about whom they give it to.</li>
    </ol>
    <p>Consequently, a lot of advice floating around online and offline
    tends to be <a
    href="https://yanngirard.typepad.com/yanns_blog/2016/09/why-advice-is-useless.html">pretty</a>
    <a
    href="https://brightside.me/inspiration-psychology/10-useless-pieces-of-advice-that-people-should-stop-giving-480710/">much</a>
    <a
    href="https://medium.com/honest-creative/why-most-advice-is-useless-5903825a4700">useless</a>.
    Even in the rationality community (which gets a lot of other things
    right), I’m rather put off by “<a
    href="https://www.lesswrong.com/tag/debugging">group debugging</a>”,
    “<a
    href="https://www.lesswrong.com/posts/P5k3PGzebd5yYrYqd/the-hamming-question">Hamming
    circles</a>“, and the “<a
    href="https://www.lesswrong.com/posts/rFjhz5Ks685xHbMXW/hammertime-day-1-bug-hunt">Hammertime</a>”.
    I see that people get value from doing these things, but most (if
    not all) value appears to come from the “side-effects” of
    advice-giving and -receiving rather than the actual content of the
    advice.</p>
    <h2 id="the-negative-way">The negative way</h2>
    <p>Considering all these arguments, I try to limit my advice-giving
    to an absolute minimum. This, as you can imagine, is becoming
    increasingly difficult as I continue <a
    href="https://kirchner-jan.github.io/minimalprior/">this
    experiment</a> of broadcasting my thoughts on a near-weekly basis.
    There are so many things I <em>want</em> to write about because I
    think I’ve figured out a truly brilliant way of doing them, but I
    stop myself so as not to embarrass my future self. Most things that
    work well for me might be Jan-specific strategies that don’t
    generalize<sup>[3]</sup>.</p>
    <div class="sidenote">
    <p>[3] </p>
    <p>And that might stop working as soon as external factors in my
    environment change.</p>
    </div>
    <p>There might be a way out, however. The great Nassim Taleb
    declared in 2019<sup>[4]</sup></p>
    <div class="sidenote">
    <p>[4] </p>
    <p>I.e. “forever ago” in internet years</p>
    </div>
    <p><a
    href="https://twitter.com/nntaleb/status/1093163028739248129?lang=en"><img
    src="https://substackcdn.com/image/twitter_name/w_96/nntaleb.jpg"
    alt="Twitter avatar for @nntaleb" />Nassim Nicholas Taleb <span
    class="citation" data-cites="nntaleb1">@nntaleb1</span>- Never take
    any advice from someone you didn’t ask for advice.</a>[3:02 PM ∙ Feb
    6, 2019</p>
    <hr />
    <p>3,133Likes696Retweets](https://twitter.com/nntaleb/status/1093163028739248129?lang=en)</p>
    <p>on Twitter. He notices the problem with this a couple of hours
    later and posts</p>
    <p><a
    href="https://twitter.com/nntaleb/status/1093259664945541120"><img
    src="https://substackcdn.com/image/twitter_name/w_96/nntaleb.jpg"
    alt="Twitter avatar for @nntaleb" />Nassim Nicholas Taleb <span
    class="citation" data-cites="nntaleb1">@nntaleb1</span>- Never take
    any positive advice from someone you didn’t ask for advice.
    (corrected to fix the meta-problem).</a>[9:26 PM ∙ Feb 6, 2019</p>
    <hr />
    <p>776Likes89Retweets](https://twitter.com/nntaleb/status/1093259664945541120)</p>
    <p>Nassim calls this strategy fancifully the <a
    href="https://coffeeandjunk.com/via-negativa/">via negativa</a>, the
    observation that <strong>our knowledge and inherent understanding of
    downsides is far more robust than what we know about
    upsides</strong>. Instead of telling people what to do, we might
    want to focus on what <em>not</em> to do. I don’t think this fixes
    all the issues with advice-giving outlined above, but it goes some
    distance towards it.</p>
    <p>Hence, this post is <em>not</em> regular old advice. It’s <em>via
    negativa</em>. I want to articulate some of the non-obvious
    productivity traps I have identified in myself and others and warn
    you about them. Before we dive in, here is a bitter lesson upfront;
    <strong>If your goal is to be productive, you should</strong> _
    <strong>work</strong>_ <strong>and not read blog posts</strong>. If
    you are looking for a way to be productive, stop reading this now
    and do whatever you’re supposed to be doing<sup>[5]</sup>.</p>
    <div class="sidenote">
    <p>[5] </p>
    <p>You’re welcome!</p>
    </div>
    <p>However, If you happen to be curious about how I do things, read
    on<sup>[6]</sup>.</p>
    <div class="sidenote">
    <p>[6] </p>
    <p>I also hope that the first group of people continues to read,<a
    href="https://en.wikipedia.org/wiki/Reverse_psychology">reverse
    psychology</a> and everything.</p>
    </div>
    <h2 id="dont-fight-the-hydra."><strong>Don’t fight the
    Hydra.</strong></h2>
    <p>Perhaps the most common failure mode I observe in myself and
    others is “getting sidetracked” or “losing focus”. It’s hard to
    pinpoint exactly what is happening, so I’ll use the (admittedly a
    bit stale) metaphor of <a
    href="https://en.wikipedia.org/wiki/Lernaean_Hydra">fighting the
    Lernaean Hydra</a> to illustrate.</p>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_77.png" />The
    metaphor might be stale, but the illustration is stellar.</p>
    <p>Imagine yourself as Heracles sent out to kill the Hydra. For
    every head you cut off, two new heads grow. As long as the Hydra
    retains at least one head, you cannot kill it. You can spend a
    lifetime and more cutting off heads, and you’ll be farther from your
    goal of killing the Hydra than when you started.</p>
    <p>The Hydra, of course, is your research problem. When researching
    a fact, you might get seduced by trivia and the <a
    href="https://www.instagram.com/depthsofwikipedia/?hl=en">depths of
    Wikipedia</a>. When proving a mathematical theorem, choosing the
    wrong strategy will lead you into an endless circle of algebraic
    transformations. And in research, more generally, there is a
    tendency not just to solve a technical problem but to <em>utterly
    demolish</em> it, i.e., solving every possible variation of the
    problem and writing a long-winded Tractatus on how you did it.</p>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_78.png" />source:
    from the internet</p>
    <p>Be wary, be very wary indeed, of engaging with a Hydra problem.
    You might be able to identify a Hydra problem by keeping track of
    the <a
    href="https://en.wikipedia.org/wiki/Branching_factor">branching
    factor</a>: how many subproblems does each step of your derivation
    introduce? If this continues to be larger than 1, your approach is
    probably incorrect or at least infeasible. This might appear
    obvious, but history is <a
    href="https://www.amazon.de/Newtonian-Revolution-I-Bernard-Cohen/dp/0511665377">full</a>
    of famous <a
    href="https://www.smithsonianmag.com/science-nature/the-evolution-of-charles-darwin-110234034/">examples</a>
    of researchers getting stuck on <a
    href="https://en.wikipedia.org/wiki/Deferent_and_epicycle">epicycles</a>.
    Researchers produced “<a
    href="https://www.lesswrong.com/s/5uZQHpecjn7955faL/p/fysgqk4CjAwhBgNYT">pseudo-answers</a>”
    to questions, but they opened more questions than closed. I observe
    the pattern in my colleagues, students, and
    myself<sup>[7]</sup>.</p>
    <div class="sidenote">
    <p>[7] </p>
    <p>I don’t want to step on anybody’s toes, but if I had to register
    a prediction, I’d predict that the <a
    href="https://www.alignmentforum.org/tag/eliciting-latent-knowledge-elk">ELK
    problem</a> turns out to be a Hydra problem. It appears to explode
    in complexity with every partial “pseudo-answer” provided.</p>
    </div>
    <p>One location where I expect a Hydra consistently is data
    analysis: When performing the wrong <em>kind</em> of analysis (f.e.
    fitting an <a
    href="https://en.wikipedia.org/wiki/Hidden_Markov_model">HMM</a>
    with no straightforward latent structure), it is tempting to “try
    things”<sup>[8]</sup> <em>ad infinitum</em>. This is bad because it
    <a href="https://en.wikipedia.org/wiki/Data_dredging">introduces
    biases into the analysis</a> and is essentially futile. Improving
    one aspect of the analysis makes every other aspect worse. Notice
    the signature of a Hydra problem, and you’re right to be scared.</p>
    <div class="sidenote">
    <p>[8] </p>
    <p>Cleaning data, changing the number of hidden states, transforming
    the representation of the observations, changing hyperparameters of
    the fitting algorithm, and repeating.</p>
    </div>
    <p>I found it fruitful to discard the framing and <a
    href="https://www.lesswrong.com/posts/9iA87EfNKnREgdTJN/conceptual-engineering-the-revolution-in-philosophy-you-ve">slice
    reality along different axes</a> in these situations. Instead of
    fitting an HMM, take a step back and take another look at simple
    statistics or the raw data. Make your implicit assumptions explicit
    and modify them. <a href="http://www.hpmor.com/chapter/8">Try to get
    a “no” instead of a “yes</a>”. And don’t be afraid to shelf
    something if it doesn’t work<sup>[9]</sup>. Otherwise, you can spend
    an unbounded amount of time and achieve almost<sup>[10]</sup>
    nothing.</p>
    <div class="sidenote">
    <p>[9] </p>
    <p>This is where “<a
    href="https://kirchner-jan.github.io/minimalprior/posts/universalprior/slightly-advanced-decision-theory?s=w">do
    all the things</a>” becomes important. You need to have multiple
    projects running in parallel to have the freedom of shelving the
    ones that don’t work.</p>
    </div>
    <div class="sidenote">
    <p>[10] </p>
    <p>I’m saying almost because even Herkules would probably improve
    his monster-killing ability through fighting the Hydra for years at
    end. Some of the skills should transfer, as long as you
    <em>eventually</em> turn to a non-Hydra problem.</p>
    </div>
    <p>Now, as stated from the onset, this is not positive advice. I do
    not know how to avoid Hydra-problems in general. Sometimes you
    <em>do</em> need to dive into the depths of Wikipedia, fight your
    way through increasingly complicated algebraic equations, or utterly
    demolish a technical problem - only to come out at the other side
    and to find the <a
    href="https://en.wikipedia.org/wiki/Andrew_Wiles">branching factor
    collapse suddenly</a>. And sometimes all the new heads of the Hydra
    that emerge <a
    href="https://en.wikipedia.org/wiki/Dartmouth_workshop">turn out to
    be</a> deep and important problems that can be (approximately)
    separated from each other. But unless the problem you solve is so
    important that you’re okay with spending a lifetime without making
    progress, don’t risk engaging with a Hydra problem.</p>
    <h2 id="one-must-imagine-sisyphus-unproductive."><strong>One must
    imagine Sisyphus unproductive</strong><a
    href="https://en.wikipedia.org/wiki/Dartmouth_workshop">.</a></h2>
    <p>I’ve spent an insane amount of time in the early 2000s manually
    adding thumbnails to my music collection in Windows Media
    Player<sup>[11]</sup>.</p>
    <div class="sidenote">
    <p>[11] </p>
    <p>I don’t know if this is a <a
    href="https://twitter.com/elhotzo/status/1352653561562357763?s=20&amp;t=_rafrNaKxhB8vyLZh5dgVQ">German
    thing</a> or a more general phenomenon.</p>
    </div>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_79.png" />Not
    my collection. I would never publically admit enjoying 30 Seconds To
    Mars.</p>
    <p>In retrospect, I did that because the resulting mosaic of album
    covers looked kind of pretty. But at the time, I told myself that
    this is a one-time investment of work and that once I’ve updated my
    entire library, I’ll only have to do a little bit of work to add the
    cover art for every new album I add. You can imagine my
    disappointment when Spotify appeared and made my thumbnail work
    useless. I’m not bringing this up because I still hold a
    grudge<sup>[12]</sup>. It’s just an illustrative example of what I
    call “overoptimizing in null space”.</p>
    <div class="sidenote">
    <p>[12] </p>
    <p>I never forgive, but I <em>do</em> forget eventually.</p>
    </div>
    <p>Let’s take that apart a bit further. You are probably already
    familiar with the <a
    href="https://en.wikipedia.org/wiki/Pareto_principle">20-80
    rule</a>: “Focus on the vital 20% of effort that produces 80% of the
    outcome.”<sup>[13]</sup> That rule is great, but it’s not “<a
    href="https://en.wikipedia.org/wiki/Constructive_proof">constructive</a>”
    and doesn’t help with <em>finding</em> the vital 20%. Also, there
    are some situations where we cannot apply the rule
    straightforwardly:</p>
    <div class="sidenote">
    <p>[13] </p>
    <p>Related is the strategy to, in the words of Nate Soares, “<a
    href="https://mindingourway.com/half-assing-it-with-everything-youve-got/">half-ass
    it with everything you’ve got</a>“.</p>
    </div>
    <ul class="incremental">
    <li><p>When writing an essay for your dream college or doing a work
    test for your dream job, you might <strong>not</strong> want to
    half-ass it. This is not a situation where you can aim for a fixed
    level of quality and get the job - by construction, you are
    competing with other people who are incentivized to <a
    href="https://en.wikipedia.org/wiki/All-pay_auction">outbid</a> you.
    So if you value the opportunity sufficiently and think you have a
    shot at outbidding your competition, you don’t want to stop at 20%
    effort. Here, the landscape is artificially designed to incentivize
    you to demonstrate the maximum of what you are capable of (which the
    interviewer is trying to estimate)<sup>[14]</sup>. The goal of your
    effort is not to solve a problem in the world but to signal your
    capability.</p>
    <div class="sidenote">
    <p>[14] </p>
    <p>There is some super interesting game theory here. These interview
    situations appear to be <a
    href="https://en.wikipedia.org/wiki/All-pay_auction">all-pay
    auctions</a> where the Nash equilibrium becomes unstable when the
    bidders’ valuation is higher than their budget? This leads to a bad
    situation where interviewees waste a lot of time and energy
    (all-pay) on jobs they won’t get. The interviewers get unrealistic
    estimates of what the candidates are capable of (nobody can sustain
    100% effort). A much nicer equilibrium would be if all the
    interviewees agreed only to put 20% effort into the interview.
    They’d waste less energy, and the interviewer would get a more
    realistic estimate of what they’ll get. But this equilibrium is
    unstable because each interviewee is incentivized to put in more
    effort to beat their competition.<br />
    Can we design a system that avoids this bad dynamic?</p>
    </div></li>
    <li><p>Sometimes the Pareto principle does not apply. Sometimes the
    <a
    href="https://en.wikipedia.org/wiki/Scope_neglect">outcome</a><em><a
    href="https://en.wikipedia.org/wiki/Scope_neglect">is</a></em><a
    href="https://en.wikipedia.org/wiki/Scope_neglect">proportional to
    the effort</a>. Or at least it takes a very long time <a
    href="https://kirchner-jan.github.io/minimalprior/posts/universalprior/slightly-advanced-decision-theory?s=w">before
    diminishing returns become noticeable</a>. There might still be <a
    href="https://forum.effectivealtruism.org/posts/pseF3ZmY7uhLtdwss/aiming-for-the-minimum-of-self-care-is-dangerous">reasons</a>
    not to invest 100% effort 100% of the time, but those are a lot less
    straightforward than “if you want more of something, do more to get
    it”.</p></li>
    <li><p>And then there is Yoda and “<a
    href="https://www.lesswrong.com/posts/WLJwTJ7uGPA5Qphbp/trying-to-try">Trying
    to Try</a>”. Sometimes it is simply a convenient trick to think of
    your effort as an “all-out effort” rather than to invest the
    cognitive overhead in calibrating how much effort you should be
    investing. This only works when the task is sufficiently
    important.</p></li>
    </ul>
    <p>These counterexamples motivate me to think of “optimization in
    null space”. In linear algebra, the null space is the part of the
    input space mapped onto <strong>0</strong>. As long as you move in
    this null space (or an affine transformation), your outcome will not
    change. If you’re more of a visual thinker, think of a 2D Mexican
    hat<sup>[15]</sup> that has a circular basin of minima.</p>
    <div class="sidenote">
    <p>[15] </p>
    <p>This term <em>feels</em> inappropriate, and Wikipedia calls it
    the “<a href="https://en.wikipedia.org/wiki/Ricker_wavelet">Ricker
    wavelet</a>” or the “Marr wavelet”. And I guess it’s a silly
    stereotype to associate the sombrero so strongly with Mexico?</p>
    </div>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32_80.png" />Remember
    the days when I created beautiful plots from scratch for you, rather
    than grabbing something from Google and adding a line by hand? I
    promise those days will come back, but there is a bit of craziness
    going on in my life.</p>
    <p>“Optimization in null space” is then an oxymoron that gestures at
    the idea of spending a lot of energy on something that doesn’t cash
    out in terms of performance. This is essentially equivalent to the
    20-80 rule but framed in terms of optimization processes.
    Interpreted through that lens, there are a few non-obvious
    heuristics that pop out:</p>
    <ul class="incremental">
    <li><p>Try to reduce overhead aggressively. Go for systems with <a
    href="https://roamresearch.com/">minimal structure and maximal
    flexibility</a>. Don’t search for <a
    href="https://jeffhuang.com/productivity_text_file/">the perfect
    note-taking system</a>; pick something and run with it. “ <em><a
    href="http://principles-wiki.net/principles:gall_s_law">A complex
    system that works is invariably found to have evolved from a simple
    system that worked.</a></em> ” If it doesn’t start paying off soon
    after starting, you might be in null space<sup>[16]</sup>.</p>
    <div class="sidenote">
    <p>[16] </p>
    <p>But what about a university education? Or learning an instrument?
    Or the marshmallow test? Here I’m happy to bite the bullet and
    assert that it’s probably a <a
    href="https://thielfellowship.org/">bad idea to continue</a> if you
    don’t enjoy uni. If you don’t enjoy the process of learning an
    instrument, you’re probably doing it wrong, and too many
    marshmallows are bad for you.</p>
    </div></li>
    <li><p>Look for things that scale. Effective altruism is a community
    built around searching for <a
    href="https://80000hours.org/articles/problem-framework/#:~:text=a%20positive%20impact%3A-,scale,-%2C%20neglectedness%2C%20solvability%20and">good
    things that scale</a>. Meeting new people <a
    href="https://colah.github.io/personal/micromarriages/">scales</a>.
    Starting new projects scales<sup>[17]</sup>. <a
    href="https://arxiv.org/abs/2001.08361">Artificial intelligence
    scales</a><sup>[18]</sup>.</p>
    <div class="sidenote">
    <p>[17] </p>
    <p>In the sense that your <a
    href="https://kirchner-jan.github.io/minimalprior/posts/universalprior/slightly-advanced-decision-theory?s=w">total
    expected outcome continues to increase</a> even if your performance
    across all the individual projects deteriorates moderately.</p>
    </div>
    <div class="sidenote">
    <p>[18] </p>
    <p>This is (part of) why I am excited about <a
    href="https://kirchner-jan.github.io/minimalprior/posts/universalprior/on-scaling-academia">automated
    research</a> and <a
    href="https://kirchner-jan.github.io/minimalprior/posts/universalprior/making-of-ian">digital
    assistants</a>.</p>
    </div></li>
    <li><p>When things start to feel noisy, but you haven’t reached your
    desired outcome yet, then go for small, robust improvements rather
    than trying to revolutionize<sup>[19]</sup>. This must be how <a
    href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode#:~:text=CLASS%20COMPETITIVE%20PROGRAMMER-,For,-artificial%20intelligence%20to">Deepmind
    built AlphaCode</a>. To reach this point, you must be slightly
    desperate.</p>
    <div class="sidenote">
    <p>[19] </p>
    <p>Here’s an anecdote that I’m dying to share: At uni, I took part
    in a <a
    href="https://en.wikipedia.org/wiki/General_game_playing">General
    Game Playing</a> where each team had to program a
    (good-old-fashioned) A.I. that can solve a range of games after only
    being provided with the rules at runtime. The only feasible strategy
    (AFAICT) is to do a <a
    href="https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#:~:text=Background%3A-,Pure%20Planning,-.%20The%20most%20basic">pure
    search</a> on the state space of the game (provided at runtime).
    There was pretty fierce competition, and some teams packed their
    general game player with a bunch of heuristics to try and guess (at
    runtime) which game they were playing so that they could do their
    search of state-space more efficiently. Our team didn’t do that.
    Instead, we read the programming language’s documentation carefully
    and wrote a highly optimized version of vanilla alpha-beta search
    that exploits all the built-in functions. Our team beat all the
    other teams by a pretty substantial margin. (I have a hard time
    hiding that I consider that piece of coursework from my undergrad to
    be the peak of my research career).</p>
    </div></li>
    </ul>
    <p>But those are, of course, only heuristics. “Via negativa” does
    not provide a rulebook to follow; it just tries to highlight major
    pitfalls. Noticing the pitfalls and avoiding them is up to you.</p>
    <h2 id="dont-listen-to-cassandra."><strong>Don’t listen to
    Cassandra.</strong></h2>
    <p>There <em>is</em> a chance that I’m taking this Greek mythology
    thing too far. Let me be clear, if you find someone who really,
    legitimately <em>is</em> Cassandra, please <em>do</em> listen to
    them. Also, please correct your <a
    href="https://www.feministcurrent.com/2020/12/23/cassandra-lives-from-politics-to-the-court-room-women-are-disbelieved/">bias
    of not believing women</a>. Also, if people talk to you, please
    listen to them or (alternatively) tell them you have to visit the
    bathroom or something. Just “not listening” is rude.</p>
    <p><img
    src="../../images/https3A2F2Fbucketeer-e05bbc84-baa3-437e-9518-adb32.jpeg" />“People
    in the wooden horse, you say? Fascinating! Say, do you happen to
    know where I can find the next latrine?”</p>
    <p>Instead, I’m trying to say that there is an overwhelming “<a
    href="https://www.youtube.com/watch?v=zC30BYR3CUk">Everything</a>”
    going on online, and our poor monkey brains cannot keep track.
    Therefore you need <em>really good filters</em>. Try having fewer
    opinions, resist the urge of joining the debate du jour, ignore most
    things that don’t make sense to you right now. It’s okay, and you’re
    only human. Somebody else (hopefully) will take the stuff you
    discard seriously. And if it were really important, it would
    probably pop up again and again.</p>
    <p>The edgelord-y version of this idea is <a
    href="https://en.wikipedia.org/wiki/Sturgeon%27s_law">Sturgeon’s
    law</a>: “ninety percent of everything is crap.”<sup>[20]</sup> I
    like the slightly more palatable “ninety percent of everything is
    not immediately useful to you.” That version is also more likely to
    be true: It would be weird if most things out there were relevant to
    _<a href="https://en.wikipedia.org/wiki/Egocentric_bias">you in
    particular</a> , _and even the objectively worst piece of science
    fiction probably made someone’s grandma very proud.</p>
    <div class="sidenote">
    <p>[20] </p>
    <p>It’s important to remember that Theodore Sturgeon was a science
    fiction author and critic. Someone who gets paid to say and write
    interesting things, not someone who gets paid to say and write
    <em>true</em> things.</p>
    </div>
    <p>What are the properties of a good filter? A really good filter
    will only let the first-order approximation of a concept get into
    long-term memory. You won’t need more to plant the concept into your
    <a
    href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a>,
    and if you ever need higher-order terms (f.e. <a
    href="https://www.cold-takes.com/learning-by-writing/">for
    writing</a>), you’ll have to go back to the source anyway. Your
    filter might also be very <a
    href="http://www2.csudh.edu/ccauthen/576f12/frankfurt__harry_-_on_bullshit.pdf">sensitive
    to bullshit</a> and discard <a
    href="https://en.wikipedia.org/wiki/Anecdotal_evidence">most
    anecdotes</a>. Instead of tracking details, track motivations.</p>
    <p>And, please, do all of that without being rude.</p>
    <h2 id="closing-thoughts">Closing thoughts</h2>
    <p>Even though I presented them as three different ideas (don’t try
    to solve Hydra problems, don’t optimize in null space, don’t try to
    pay attention to everything), they all circle around one common
    theme: be honest with yourself about your limitations, notice when
    you’re going down a rabbit hole, and constantly recalibrate. Try to
    have a good epistemic.</p>
    <p>Phrased like this, I don’t think this advice<sup>[21]</sup> is
    controversial (or very novel<sup>[22]</sup>). The value I gained
    from writing this is that I now have a more explicit understanding
    of how I operate (sometimes/rarely). The value for a hypothetical
    reader that has come to this point might be that they
    update<sup>[23]</sup> on the relative importance of my advice over
    other people’s advice. Or perhaps you feel motivated to make your
    M.O. explicit? Feel free to leave your thoughts in the comments;
    always curious to hear what you think (most things people tell me
    directly pass my filter just fine). Or consider signing up for the
    newsletter to get notified whenever I write something new!</p>
    <div class="sidenote">
    <p>[21] </p>
    <p>Yeah, I admit that that is what the essay turned into. Shame on
    me.</p>
    </div>
    <div class="sidenote">
    <p>[22] </p>
    <p>As noted, I was mostly remixing/slightly modifying Thomas Kuhn’s
    scientific paradigms, the 20-80 rule, and Sturgeon’s law.</p>
    </div>
    <div class="sidenote">
    <p>[23] </p>
    <p>I’m staying intentionally unspecific about the direction of the
    update.</p>
    </div>
    <div class="debug-grid"></div>
  <script src="../../index.js"></script>
</body>

</html>