<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="" >

<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <meta name="author" content="Jan Kirchner" />
      <meta name="dcterms.date" content="2022-03-06" />
        <title>minimalprior</title>
    <link rel="stylesheet" href="../../reset.css" />
    <link rel="stylesheet" href="../../index.css" />
      </head>

<body>
    <table class="header">
    <tr>
      <td colspan="2" rowspan="2" class="width-auto">
        <h1 class="title">minimalprior</h1>
        <span class="subtitle">a spinoff</span>
      </td>
      <th>Updated</th>
      <td class="width-min"><time style="white-space: pre;">2022-03-06</time></td>
    </tr>
    <tr>
      <th class="width-min">Author</th>
      <td class="width-auto"><a href="https://universalprior.substack.com/">Jan
Kirchner</a></td>
    </tr>
  </table>
      <nav id="TOC" role="doc-toc">
        <ul class="incremental">
        <li><a href="#against-advice"
        id="toc-against-advice"><strong>Against advice</strong></a></li>
        <li><a href="#the-negative-way" id="toc-the-negative-way">The
        negative way</a></li>
        <li><a href="#dont-fight-the-hydra."
        id="toc-dont-fight-the-hydra."><strong>Don’t fight the
        Hydra.</strong></a></li>
        <li><a href="#one-must-imagine-sisyphus-unproductive."
        id="toc-one-must-imagine-sisyphus-unproductive."><strong>One
        must imagine Sisyphus unproductive</strong>.</a></li>
        <li><a href="#dont-listen-to-cassandra."
        id="toc-dont-listen-to-cassandra."><strong>Don’t listen to
        Cassandra.</strong></a></li>
        <li><a href="#closing-thoughts"
        id="toc-closing-thoughts">Closing thoughts</a></li>
        </ul>
  </nav>
    <h1 id="against-advice"><strong>Against advice</strong></h1>
    <blockquote>
    <p>Be careful whose advice you buy, but be patient with those who
    supply it. Advice is a form of nostalgia, dispensing it is a way of
    fishing the past from the disposal, wiping it off, painting over the
    ugly parts and recycling it for more than it’s worth. - <a
    href="https://www.youtube.com/watch?v=sTJ7AzBIJoI&amp;ab_channel=steffyweffy777">Everybody’s
    Free To Wear Sunscreen</a></p>
    </blockquote>
    <p>…</p>
    <p>Yeah, I’m not a huge fan of advice.</p>
    <p>I think there are many good side effects of giving and receiving
    advice. The act of giving advice is essentially an <a
    href="https://universalprior.substack.com/p/trust-maximizing-agi?s=w">expression
    of trust</a>, “asking for help” is a <a
    href="https://torch.io/blog/leadership-the-power-of-asking-for-help/">social
    superpower</a>, and the downsides of being exposed to information
    are <em>usually</em> rather low<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-1-49610622">1</a>.
    But those are just side effects; the actual core purpose of advice
    (exchanging relevant and helpful information) is surprisingly hard
    to get right: 1. Causality is <a
    href="https://arxiv.org/pdf/2109.11513.pdf">complicated</a>. <a
    href="http://www.scholarpedia.org/article/Reinforcement_learning#.28Temporal.29_Credit_Assignment_Problem">Figuring
    out why you succeeded</a> is hard, and the story you tell yourself
    about it is probably wrong.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fff5b56ac-367b-4878-8f96-a5677b5b57fd_635x945.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fff5b56ac-367b-4878-8f96-a5677b5b57fd_635x945.png" /></a><a
    href="https://xkcd.com/1827/">source</a> 1. For almost any piece of
    advice out there, you can find <a
    href="https://slatestarcodex.com/2014/03/24/should-you-reverse-any-advice-you-hear/">reverse
    advice</a>, i.e.</p>
    <blockquote>
    <p>“You need to stop being so hard on yourself, remember you are
    your own worst critic” versus “Stop making excuses for yourself, you
    will never be able to change until you admit you’ve hit bottom.” <a
    href="https://slatestarcodex.com/2014/03/24/should-you-reverse-any-advice-you-hear/">SSC</a></p>
    </blockquote>
    <p>and because of your <a
    href="https://slatestarcodex.com/2017/10/02/different-worlds/">social
    bubble</a>, you might be exposed to advice with exactly the wrong
    polarity<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-2-49610622">2</a>.
    1. The people with the most relevant insight are probably busy
    <em>doing</em> stuff, leaving the people with a lot of free time on
    their hands to dominate the advice-giving market. So most people who
    want to give (or sell) advice do not have the relevant insight to
    give <em>good</em> advice. This effect corroborates the <a
    href="https://marginalrevolution.com/marginalrevolution/2021/12/two-all-purpose-pieces-of-advice-small-groups-and-mentors.html">importance
    of having mentors</a>; even busy people want to give advice but are
    more selective about whom they give it to.</p>
    <p>Consequently, a lot of advice floating around online and offline
    tends to be <a
    href="https://yanngirard.typepad.com/yanns_blog/2016/09/why-advice-is-useless.html">pretty</a>
    <a
    href="https://brightside.me/inspiration-psychology/10-useless-pieces-of-advice-that-people-should-stop-giving-480710/">much</a>
    <a
    href="https://medium.com/honest-creative/why-most-advice-is-useless-5903825a4700">useless</a>.
    Even in the rationality community (which gets a lot of other things
    right), I’m rather put off by “<a
    href="https://www.lesswrong.com/tag/debugging">group debugging</a>”,
    “<a
    href="https://www.lesswrong.com/posts/P5k3PGzebd5yYrYqd/the-hamming-question">Hamming
    circles</a>“, and the “<a
    href="https://www.lesswrong.com/posts/rFjhz5Ks685xHbMXW/hammertime-day-1-bug-hunt">Hammertime</a>”.
    I see that people get value from doing these things, but most (if
    not all) value appears to come from the “side-effects” of
    advice-giving and -receiving rather than the actual content of the
    advice.</p>
    <h1 id="the-negative-way">The negative way</h1>
    <p>Considering all these arguments, I try to limit my advice-giving
    to an absolute minimum. This, as you can imagine, is becoming
    increasingly difficult as I continue <a
    href="https://universalprior.substack.com/">this experiment</a> of
    broadcasting my thoughts on a near-weekly basis. There are so many
    things I <em>want</em> to write about because I think I’ve figured
    out a truly brilliant way of doing them, but I stop myself so as not
    to embarrass my future self. Most things that work well for me might
    be Jan-specific strategies that don’t generalize<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-3-49610622">3</a>.</p>
    <p>There might be a way out, however. The great Nassim Taleb
    declared in 2019<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-4-49610622">4</a></p>
    <p><a
    href="https://twitter.com/nntaleb/status/1093163028739248129?lang=en"><img
    src="https://substackcdn.com/image/twitter_name/w_96/nntaleb.jpg"
    alt="Twitter avatar for @nntaleb" />Nassim Nicholas Taleb <span
    class="citation" data-cites="nntaleb1">@nntaleb1</span>- Never take
    any advice from someone you didn’t ask for advice.</a>[3:02 PM ∙ Feb
    6, 2019</p>
    <hr />
    <p>3,133Likes696Retweets](https://twitter.com/nntaleb/status/1093163028739248129?lang=en)</p>
    <p>on Twitter. He notices the problem with this a couple of hours
    later and posts</p>
    <p><a
    href="https://twitter.com/nntaleb/status/1093259664945541120"><img
    src="https://substackcdn.com/image/twitter_name/w_96/nntaleb.jpg"
    alt="Twitter avatar for @nntaleb" />Nassim Nicholas Taleb <span
    class="citation" data-cites="nntaleb1">@nntaleb1</span>- Never take
    any positive advice from someone you didn’t ask for advice.
    (corrected to fix the meta-problem).</a>[9:26 PM ∙ Feb 6, 2019</p>
    <hr />
    <p>776Likes89Retweets](https://twitter.com/nntaleb/status/1093259664945541120)</p>
    <p>Nassim calls this strategy fancifully the <a
    href="https://coffeeandjunk.com/via-negativa/">via negativa</a>, the
    observation that <strong>our knowledge and inherent understanding of
    downsides is far more robust than what we know about
    upsides</strong>. Instead of telling people what to do, we might
    want to focus on what <em>not</em> to do. I don’t think this fixes
    all the issues with advice-giving outlined above, but it goes some
    distance towards it.</p>
    <p>Hence, this post is <em>not</em> regular old advice. It’s <em>via
    negativa</em>. I want to articulate some of the non-obvious
    productivity traps I have identified in myself and others and warn
    you about them. Before we dive in, here is a bitter lesson upfront;
    <strong>If your goal is to be productive, you should</strong> _
    <strong>work</strong>_ <strong>and not read blog posts</strong>. If
    you are looking for a way to be productive, stop reading this now
    and do whatever you’re supposed to be doing<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-5-49610622">5</a>.</p>
    <p>However, If you happen to be curious about how I do things, read
    on<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-6-49610622">6</a>.</p>
    <h1 id="dont-fight-the-hydra."><strong>Don’t fight the
    Hydra.</strong></h1>
    <p>Perhaps the most common failure mode I observe in myself and
    others is “getting sidetracked” or “losing focus”. It’s hard to
    pinpoint exactly what is happening, so I’ll use the (admittedly a
    bit stale) metaphor of <a
    href="https://en.wikipedia.org/wiki/Lernaean_Hydra">fighting the
    Lernaean Hydra</a> to illustrate.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe146847f-21e9-4275-b234-beb4449b18fa_381x265.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe146847f-21e9-4275-b234-beb4449b18fa_381x265.png" /></a>The
    metaphor might be stale, but the illustration is stellar.</p>
    <p>Imagine yourself as Heracles sent out to kill the Hydra. For
    every head you cut off, two new heads grow. As long as the Hydra
    retains at least one head, you cannot kill it. You can spend a
    lifetime and more cutting off heads, and you’ll be farther from your
    goal of killing the Hydra than when you started.</p>
    <p>The Hydra, of course, is your research problem. When researching
    a fact, you might get seduced by trivia and the <a
    href="https://www.instagram.com/depthsofwikipedia/?hl=en">depths of
    Wikipedia</a>. When proving a mathematical theorem, choosing the
    wrong strategy will lead you into an endless circle of algebraic
    transformations. And in research, more generally, there is a
    tendency not just to solve a technical problem but to <em>utterly
    demolish</em> it, i.e., solving every possible variation of the
    problem and writing a long-winded Tractatus on how you did it.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F18e49fc6-8900-4221-b9f0-20584fd14bb3_1122x1122.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F18e49fc6-8900-4221-b9f0-20584fd14bb3_1122x1122.png" /></a>source:
    from the internet</p>
    <p>Be wary, be very wary indeed, of engaging with a Hydra problem.
    You might be able to identify a Hydra problem by keeping track of
    the <a
    href="https://en.wikipedia.org/wiki/Branching_factor">branching
    factor</a>: how many subproblems does each step of your derivation
    introduce? If this continues to be larger than 1, your approach is
    probably incorrect or at least infeasible. This might appear
    obvious, but history is <a
    href="https://www.amazon.de/Newtonian-Revolution-I-Bernard-Cohen/dp/0511665377">full</a>
    of famous <a
    href="https://www.smithsonianmag.com/science-nature/the-evolution-of-charles-darwin-110234034/">examples</a>
    of researchers getting stuck on <a
    href="https://en.wikipedia.org/wiki/Deferent_and_epicycle">epicycles</a>.
    Researchers produced “<a
    href="https://www.lesswrong.com/s/5uZQHpecjn7955faL/p/fysgqk4CjAwhBgNYT">pseudo-answers</a>”
    to questions, but they opened more questions than closed. I observe
    the pattern in my colleagues, students, and myself<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-7-49610622">7</a>.</p>
    <p>One location where I expect a Hydra consistently is data
    analysis: When performing the wrong <em>kind</em> of analysis (f.e.
    fitting an <a
    href="https://en.wikipedia.org/wiki/Hidden_Markov_model">HMM</a>
    with no straightforward latent structure), it is tempting to “try
    things<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-8-49610622">8</a>”
    <em>ad infinitum</em>. This is bad because it <a
    href="https://en.wikipedia.org/wiki/Data_dredging">introduces biases
    into the analysis</a> and is essentially futile. Improving one
    aspect of the analysis makes every other aspect worse. Notice the
    signature of a Hydra problem, and you’re right to be scared.</p>
    <p>I found it fruitful to discard the framing and <a
    href="https://www.lesswrong.com/posts/9iA87EfNKnREgdTJN/conceptual-engineering-the-revolution-in-philosophy-you-ve">slice
    reality along different axes</a> in these situations. Instead of
    fitting an HMM, take a step back and take another look at simple
    statistics or the raw data. Make your implicit assumptions explicit
    and modify them. <a href="http://www.hpmor.com/chapter/8">Try to get
    a “no” instead of a “yes</a>”. And don’t be afraid to shelf
    something if it doesn’t work<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-9-49610622">9</a>.
    Otherwise, you can spend an unbounded amount of time and achieve
    almost<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-10-49610622">10</a>
    nothing.</p>
    <p>Now, as stated from the onset, this is not positive advice. I do
    not know how to avoid Hydra-problems in general. Sometimes you
    <em>do</em> need to dive into the depths of Wikipedia, fight your
    way through increasingly complicated algebraic equations, or utterly
    demolish a technical problem - only to come out at the other side
    and to find the <a
    href="https://en.wikipedia.org/wiki/Andrew_Wiles">branching factor
    collapse suddenly</a>. And sometimes all the new heads of the Hydra
    that emerge <a
    href="https://en.wikipedia.org/wiki/Dartmouth_workshop">turn out to
    be</a> deep and important problems that can be (approximately)
    separated from each other. But unless the problem you solve is so
    important that you’re okay with spending a lifetime without making
    progress, don’t risk engaging with a Hydra problem.</p>
    <h1 id="one-must-imagine-sisyphus-unproductive."><strong>One must
    imagine Sisyphus unproductive</strong><a
    href="https://en.wikipedia.org/wiki/Dartmouth_workshop">.</a></h1>
    <p>I’ve spent an insane amount of time in the early 2000s manually
    adding thumbnails to my music collection in Windows Media Player<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-11-49610622">11</a>.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcee1ad13-867d-47dd-98c9-44bc24079013_1202x857.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcee1ad13-867d-47dd-98c9-44bc24079013_1202x857.png" /></a>Not
    my collection. I would never publically admit enjoying 30 Seconds To
    Mars.</p>
    <p>In retrospect, I did that because the resulting mosaic of album
    covers looked kind of pretty. But at the time, I told myself that
    this is a one-time investment of work and that once I’ve updated my
    entire library, I’ll only have to do a little bit of work to add the
    cover art for every new album I add. You can imagine my
    disappointment when Spotify appeared and made my thumbnail work
    useless. I’m not bringing this up because I still hold a grudge<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-12-49610622">12</a>.
    It’s just an illustrative example of what I call “overoptimizing in
    null space”.</p>
    <p>Let’s take that apart a bit further. You are probably already
    familiar with the <a
    href="https://en.wikipedia.org/wiki/Pareto_principle">20-80
    rule</a>: “Focus on the vital 20% of effort that produces 80% of the
    outcome.”<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-13-49610622">13</a>
    That rule is great, but it’s not “<a
    href="https://en.wikipedia.org/wiki/Constructive_proof">constructive</a>”
    and doesn’t help with <em>finding</em> the vital 20%. Also, there
    are some situations where we cannot apply the rule
    straightforwardly:</p>
    <ul class="incremental">
    <li><p>When writing an essay for your dream college or doing a work
    test for your dream job, you might <strong>not</strong> want to
    half-ass it. This is not a situation where you can aim for a fixed
    level of quality and get the job - by construction, you are
    competing with other people who are incentivized to <a
    href="https://en.wikipedia.org/wiki/All-pay_auction">outbid</a> you.
    So if you value the opportunity sufficiently and think you have a
    shot at outbidding your competition, you don’t want to stop at 20%
    effort. Here, the landscape is artificially designed to incentivize
    you to demonstrate the maximum of what you are capable of (which the
    interviewer is trying to estimate)<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-14-49610622">14</a>.
    The goal of your effort is not to solve a problem in the world but
    to signal your capability.</p></li>
    <li><p>Sometimes the Pareto principle does not apply. Sometimes the
    <a
    href="https://en.wikipedia.org/wiki/Scope_neglect">outcome</a><em><a
    href="https://en.wikipedia.org/wiki/Scope_neglect">is</a></em><a
    href="https://en.wikipedia.org/wiki/Scope_neglect">proportional to
    the effort</a>. Or at least it takes a very long time <a
    href="https://universalprior.substack.com/p/slightly-advanced-decision-theory?s=w">before
    diminishing returns become noticeable</a>. There might still be <a
    href="https://forum.effectivealtruism.org/posts/pseF3ZmY7uhLtdwss/aiming-for-the-minimum-of-self-care-is-dangerous">reasons</a>
    not to invest 100% effort 100% of the time, but those are a lot less
    straightforward than “if you want more of something, do more to get
    it”.</p></li>
    <li><p>And then there is Yoda and “<a
    href="https://www.lesswrong.com/posts/WLJwTJ7uGPA5Qphbp/trying-to-try">Trying
    to Try</a>”. Sometimes it is simply a convenient trick to think of
    your effort as an “all-out effort” rather than to invest the
    cognitive overhead in calibrating how much effort you should be
    investing. This only works when the task is sufficiently
    important.</p></li>
    </ul>
    <p>These counterexamples motivate me to think of “optimization in
    null space”. In linear algebra, the null space is the part of the
    input space mapped onto <strong>0</strong>. As long as you move in
    this null space (or an affine transformation), your outcome will not
    change. If you’re more of a visual thinker, think of a 2D Mexican
    hat<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-15-49610622">15</a>
    that has a circular basin of minima.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8a8eba4f-a00b-4fdb-a3d9-0b37f5628a69_440x220.png"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8a8eba4f-a00b-4fdb-a3d9-0b37f5628a69_440x220.png" /></a>Remember
    the days when I created beautiful plots from scratch for you, rather
    than grabbing something from Google and adding a line by hand? I
    promise those days will come back, but there is a bit of craziness
    going on in my life.</p>
    <p>“Optimization in null space” is then an oxymoron that gestures at
    the idea of spending a lot of energy on something that doesn’t cash
    out in terms of performance. This is essentially equivalent to the
    20-80 rule but framed in terms of optimization processes.
    Interpreted through that lens, there are a few non-obvious
    heuristics that pop out:</p>
    <ul class="incremental">
    <li><p>Try to reduce overhead aggressively. Go for systems with <a
    href="https://roamresearch.com/">minimal structure and maximal
    flexibility</a>. Don’t search for <a
    href="https://jeffhuang.com/productivity_text_file/">the perfect
    note-taking system</a>; pick something and run with it. “ <em><a
    href="http://principles-wiki.net/principles:gall_s_law">A complex
    system that works is invariably found to have evolved from a simple
    system that worked.</a></em> ” If it doesn’t start paying off soon
    after starting, you might be in null space<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-16-49610622">16</a>.</p></li>
    <li><p>Look for things that scale. Effective altruism is a community
    built around searching for <a
    href="https://80000hours.org/articles/problem-framework/#:~:text=a%20positive%20impact%3A-,scale,-%2C%20neglectedness%2C%20solvability%20and">good
    things that scale</a>. Meeting new people <a
    href="https://colah.github.io/personal/micromarriages/">scales</a>.
    Starting new projects scales<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-17-49610622">17</a>.
    <a href="https://arxiv.org/abs/2001.08361">Artificial intelligence
    scales</a><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-18-49610622">18</a>.</p></li>
    <li><p>When things start to feel noisy, but you haven’t reached your
    desired outcome yet, then go for small, robust improvements rather
    than trying to revolutionize<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-19-49610622">19</a>.
    This must be how <a
    href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode#:~:text=CLASS%20COMPETITIVE%20PROGRAMMER-,For,-artificial%20intelligence%20to">Deepmind
    built AlphaCode</a>. To reach this point, you must be slightly
    desperate.</p></li>
    </ul>
    <p>But those are, of course, only heuristics. “Via negativa” does
    not provide a rulebook to follow; it just tries to highlight major
    pitfalls. Noticing the pitfalls and avoiding them is up to you.</p>
    <h1 id="dont-listen-to-cassandra."><strong>Don’t listen to
    Cassandra.</strong></h1>
    <p>There <em>is</em> a chance that I’m taking this Greek mythology
    thing too far. Let me be clear, if you find someone who really,
    legitimately <em>is</em> Cassandra, please <em>do</em> listen to
    them. Also, please correct your <a
    href="https://www.feministcurrent.com/2020/12/23/cassandra-lives-from-politics-to-the-court-room-women-are-disbelieved/">bias
    of not believing women</a>. Also, if people talk to you, please
    listen to them or (alternatively) tell them you have to visit the
    bathroom or something. Just “not listening” is rude.</p>
    <p><a
    href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b8dffe-e736-423b-a9e7-e840fc5c48fd_562x1136.jpeg"><img
    src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2b8dffe-e736-423b-a9e7-e840fc5c48fd_562x1136.jpeg" /></a>“People
    in the wooden horse, you say? Fascinating! Say, do you happen to
    know where I can find the next latrine?”</p>
    <p>Instead, I’m trying to say that there is an overwhelming “<a
    href="https://www.youtube.com/watch?v=zC30BYR3CUk">Everything</a>”
    going on online, and our poor monkey brains cannot keep track.
    Therefore you need <em>really good filters</em>. Try having fewer
    opinions, resist the urge of joining the debate du jour, ignore most
    things that don’t make sense to you right now. It’s okay, and you’re
    only human. Somebody else (hopefully) will take the stuff you
    discard seriously. And if it were really important, it would
    probably pop up again and again.</p>
    <p>The edgelord-y version of this idea is <a
    href="https://en.wikipedia.org/wiki/Sturgeon%27s_law">Sturgeon’s
    law</a>: “ninety percent of everything is crap<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-20-49610622">20</a>.”
    I like the slightly more palatable “ninety percent of everything is
    not immediately useful to you.” That version is also more likely to
    be true: It would be weird if most things out there were relevant to
    _<a href="https://en.wikipedia.org/wiki/Egocentric_bias">you in
    particular</a> , _and even the objectively worst piece of science
    fiction probably made someone’s grandma very proud.</p>
    <p>What are the properties of a good filter? A really good filter
    will only let the first-order approximation of a concept get into
    long-term memory. You won’t need more to plant the concept into your
    <a
    href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a>,
    and if you ever need higher-order terms (f.e. <a
    href="https://www.cold-takes.com/learning-by-writing/">for
    writing</a>), you’ll have to go back to the source anyway. Your
    filter might also be very <a
    href="http://www2.csudh.edu/ccauthen/576f12/frankfurt__harry_-_on_bullshit.pdf">sensitive
    to bullshit</a> and discard <a
    href="https://en.wikipedia.org/wiki/Anecdotal_evidence">most
    anecdotes</a>. Instead of tracking details, track motivations.</p>
    <p>And, please, do all of that without being rude.</p>
    <h1 id="closing-thoughts">Closing thoughts</h1>
    <p>Even though I presented them as three different ideas (don’t try
    to solve Hydra problems, don’t optimize in null space, don’t try to
    pay attention to everything), they all circle around one common
    theme: be honest with yourself about your limitations, notice when
    you’re going down a rabbit hole, and constantly recalibrate. Try to
    have a good epistemic.</p>
    <p>Phrased like this, I don’t think this advice<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-21-49610622">21</a>
    is controversial (or very novel<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-22-49610622">22</a>).
    The value I gained from writing this is that I now have a more
    explicit understanding of how I operate (sometimes/rarely). The
    value for a hypothetical reader that has come to this point might be
    that they update<a
    href="https://universalprior.substack.com/p/via-productiva#footnote-23-49610622">23</a>
    on the relative importance of my advice over other people’s advice.
    Or perhaps you feel motivated to make your M.O. explicit? Feel free
    to leave your thoughts in the comments; always curious to hear what
    you think (most things people tell me directly pass my filter just
    fine). Or consider signing up for the newsletter to get notified
    whenever I write something new!</p>
    <p>Subscribe</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-1-49610622">1</a></p>
    <p>Unless somebody manages to trick you into <a
    href="https://stevemay.com/category/wisdom/#:~:text=told%20his%20grandchild%3A%20%E2%80%9C-,If,-you%20see%20a">bear-assisted
    suicide</a>.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-2-49610622">2</a></p>
    <p>I.e. addicts that are part of a <a
    href="https://www.ncbi.nlm.nih.gov/books/NBK248421/">drug
    culture</a> might get the advice to take more drugs. Or rationalists
    might get the advice to <a
    href="https://www.lesswrong.com/posts/qmXqHKpgRfg83Nif9/how-to-ignore-your-emotions-while-also-thinking-you-re">use
    more rationality techniques</a>.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-3-49610622">3</a></p>
    <p>And that might stop working as soon as external factors in my
    environment change.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-4-49610622">4</a></p>
    <p>I.e. “forever ago” in internet years</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-5-49610622">5</a></p>
    <p>You’re welcome!</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-6-49610622">6</a></p>
    <p>I also hope that the first group of people continues to read,<a
    href="https://en.wikipedia.org/wiki/Reverse_psychology">reverse
    psychology</a> and everything.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-7-49610622">7</a></p>
    <p>I don’t want to step on anybody’s toes, but if I had to register
    a prediction, I’d predict that the <a
    href="https://www.alignmentforum.org/tag/eliciting-latent-knowledge-elk">ELK
    problem</a> turns out to be a Hydra problem. It appears to explode
    in complexity with every partial “pseudo-answer” provided.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-8-49610622">8</a></p>
    <p>Cleaning data, changing the number of hidden states, transforming
    the representation of the observations, changing hyperparameters of
    the fitting algorithm, and repeating.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-9-49610622">9</a></p>
    <p>This is where “<a
    href="https://universalprior.substack.com/p/slightly-advanced-decision-theory?s=w">do
    all the things</a>” becomes important. You need to have multiple
    projects running in parallel to have the freedom of shelving the
    ones that don’t work.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-10-49610622">10</a></p>
    <p>I’m saying almost because even Herkules would probably improve
    his monster-killing ability through fighting the Hydra for years at
    end. Some of the skills should transfer, as long as you
    <em>eventually</em> turn to a non-Hydra problem.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-11-49610622">11</a></p>
    <p>I don’t know if this is a <a
    href="https://twitter.com/elhotzo/status/1352653561562357763?s=20&amp;t=_rafrNaKxhB8vyLZh5dgVQ">German
    thing</a> or a more general phenomenon.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-12-49610622">12</a></p>
    <p>I never forgive, but I <em>do</em> forget eventually.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-13-49610622">13</a></p>
    <p>Related is the strategy to, in the words of Nate Soares, “<a
    href="https://mindingourway.com/half-assing-it-with-everything-youve-got/">half-ass
    it with everything you’ve got</a>“.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-14-49610622">14</a></p>
    <p>There is some super interesting game theory here. These interview
    situations appear to be <a
    href="https://en.wikipedia.org/wiki/All-pay_auction">all-pay
    auctions</a> where the Nash equilibrium becomes unstable when the
    bidders’ valuation is higher than their budget? This leads to a bad
    situation where interviewees waste a lot of time and energy
    (all-pay) on jobs they won’t get. The interviewers get unrealistic
    estimates of what the candidates are capable of (nobody can sustain
    100% effort). A much nicer equilibrium would be if all the
    interviewees agreed only to put 20% effort into the interview.
    They’d waste less energy, and the interviewer would get a more
    realistic estimate of what they’ll get. But this equilibrium is
    unstable because each interviewee is incentivized to put in more
    effort to beat their competition.<br />
    Can we design a system that avoids this bad dynamic?</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-15-49610622">15</a></p>
    <p>This term <em>feels</em> inappropriate, and Wikipedia calls it
    the “<a href="https://en.wikipedia.org/wiki/Ricker_wavelet">Ricker
    wavelet</a>” or the “Marr wavelet”. And I guess it’s a silly
    stereotype to associate the sombrero so strongly with Mexico?</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-16-49610622">16</a></p>
    <p>But what about a university education? Or learning an instrument?
    Or the marshmallow test? Here I’m happy to bite the bullet and
    assert that it’s probably a <a
    href="https://thielfellowship.org/">bad idea to continue</a> if you
    don’t enjoy uni. If you don’t enjoy the process of learning an
    instrument, you’re probably doing it wrong, and too many
    marshmallows are bad for you.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-17-49610622">17</a></p>
    <p>In the sense that your <a
    href="https://universalprior.substack.com/p/slightly-advanced-decision-theory?s=w">total
    expected outcome continues to increase</a> even if your performance
    across all the individual projects deteriorates moderately.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-18-49610622">18</a></p>
    <p>This is (part of) why I am excited about <a
    href="https://universalprior.substack.com/p/on-scaling-academia">automated
    research</a> and <a
    href="https://universalprior.substack.com/p/making-of-ian">digital
    assistants</a>.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-19-49610622">19</a></p>
    <p>Here’s an anecdote that I’m dying to share: At uni, I took part
    in a <a
    href="https://en.wikipedia.org/wiki/General_game_playing">General
    Game Playing</a> where each team had to program a
    (good-old-fashioned) A.I. that can solve a range of games after only
    being provided with the rules at runtime. The only feasible strategy
    (AFAICT) is to do a <a
    href="https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#:~:text=Background%3A-,Pure%20Planning,-.%20The%20most%20basic">pure
    search</a> on the state space of the game (provided at runtime).
    There was pretty fierce competition, and some teams packed their
    general game player with a bunch of heuristics to try and guess (at
    runtime) which game they were playing so that they could do their
    search of state-space more efficiently. Our team didn’t do that.
    Instead, we read the programming language’s documentation carefully
    and wrote a highly optimized version of vanilla alpha-beta search
    that exploits all the built-in functions. Our team beat all the
    other teams by a pretty substantial margin. (I have a hard time
    hiding that I consider that piece of coursework from my undergrad to
    be the peak of my research career).</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-20-49610622">20</a></p>
    <p>It’s important to remember that Theodore Sturgeon was a science
    fiction author and critic. Someone who gets paid to say and write
    interesting things, not someone who gets paid to say and write
    <em>true</em> things.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-21-49610622">21</a></p>
    <p>Yeah, I admit that that is what the essay turned into. Shame on
    me.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-22-49610622">22</a></p>
    <p>As noted, I was mostly remixing/slightly modifying Thomas Kuhn’s
    scientific paradigms, the 20-80 rule, and Sturgeon’s law.</p>
    <p><a
    href="https://universalprior.substack.com/p/via-productiva#footnote-anchor-23-49610622">23</a></p>
    <p>I’m staying intentionally unspecific about the direction of the
    update.</p>
    <div class="debug-grid"></div>
  <script src="index.js"></script>
</body>

</html>